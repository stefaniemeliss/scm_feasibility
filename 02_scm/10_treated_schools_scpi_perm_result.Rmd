---
title: "Power analysis with *scpi* package"
author: "Stefanie Meliss"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    self_contained: true
---

```{r setup, include=FALSE}
options(scipen = 999)
knitr::opts_chunk$set(echo = TRUE)

# Clear the workspace and run garbage collection
rm(list = ls())
gc()

# load libraries
library(kableExtra)
library(dplyr)
library(data.table)
library(scpi)
library(lme4)

# create function to source code
source_code <- function(root_dir_name = "code", target_repo = "helper_functions", branch = "main", file_name = "file.R") {
  
  # construct URL
  git_url <- paste0("https://raw.githubusercontent.com/stefaniemeliss/", target_repo, "/", branch, "/", file_name)
  
  # attempt to download from github
  tempp_file <- tempfile(fileext = ".R")
  
  # run processing with the parameters
  message <- tryCatch({
    curl::curl_download(git_url, tempp_file, quiet = F)
  }, error = function(e) {
    return(error = paste("Error in curl::curl_download:", e$message))
  })

  if(!grepl("Error", message)) {
    
    # if successful, source file
    source(tempp_file)
    remove(tempp_file)
    
  } else { # load local copy of file
    
    # Get the current working directory
    current_dir <- getwd()
    
    # Split the current directory into its components
    dir_components <- strsplit(current_dir, "/")[[1]]
    
    # Identify the root directory dynamically based on the provided root directory name
    root_index <- which(dir_components == root_dir_name)
    if (length(root_index) == 0) {
      stop(paste("Root directory", root_dir_name, "not found in the current path"))
    }
    root_dir <- do.call(file.path, as.list(dir_components[1:root_index]))
    
    # Identify the subdirectory one level below the root and construct its absolute path
    project_repo <- dir_components[root_index + 1]
    dir <- file.path(root_dir, project_repo)
    
    if (target_repo != project_repo) {
      dir <- gsub(project_repo, target_repo, dir) 
    }
    
    # Construct the full file path
    file_path <- file.path(dir, file_name)
    
    # Print the directory and file path for debugging
    print(paste("Directory:", dir))
    print(paste("File path:", file_path))
    
    # Source the file into the parent frame
    source(file_path, local = parent.frame())
  }
}

# source functions
source_code(target_repo = "scm_feasibility", file_name = "functions.R")

# Define the base directory
dir <- get_directory()
dir_data <- file.path(dir, "data")
dir_misc <- file.path(dir, "misc")

# get file stem name
file_stem <- get_file_stem()

# copy data #
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_swf.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_pupils.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_search.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_groups.csv"), dir_data, overwrite = T)

# load data #

swf <- fread(file.path(dir_data, "data_swf.csv"))
pup <- fread(file.path(dir_data, "data_pupils.csv"))
est <- fread(file.path(dir_data, "data_establishments_search.csv"), na.strings = "")
groups <- fread(file.path(dir_data, "data_establishments_groups.csv"), na.strings = "")

# process data establishments #

# load in file with timeseries desc
summary <- read.csv(file.path(dir, "02_scm", "interim",  "02_treated_schools_filter_donor_pool_out.csv"))

# only select schools with sufficient donor pool
summary <- subset(summary, n_pool >= 50)

# create df_region as reference
df_region <- unique(summary[, c("laestab", "school", "same", "neighbouring")])
```

```{r nat, include=F}
dv <- "pupil_to_qual_teacher_ratio"

# determine laestabs currently open
list_laestab <- est %>%
  filter(grepl("Open", establishmentstatus_name)) %>%
  filter(grepl("ary|All", phaseofeducation_name)) %>%
  pull(laestab) %>%
  unique()

# Perform the data transformation and filtering
z <- swf %>%
  filter(laestab %in% list_laestab) %>%
  # Select relevant columns from the data frame
  select(time_period, laestab, school, urn, !!sym(dv))

# Add MAT information to the dataset
# Create lookup table with relevant group information (avoiding duplicates)
lookup <- est[grepl("Open", establishmentstatus_name) & laestab %in% list_laestab, c("laestab", "establishmentname", "gor_name", "phaseofeducation_name", "opendate")]
lookup <- lookup[!duplicated(lookup), ]
df <- merge(z, lookup, by = "laestab", all.x = T)

# ---- Longitudinal data filtering ----

# Remove any NA years at the beginning of the timeseries
# Create a cumulative sum of non-NA values starting from the first non-NA value encountered.
# cum_non_na remain zero as long as the values are NAs
df <- df %>%
  group_by(laestab) %>%
  # sort ascending by timeseries - BEGINNING
  arrange(time_period) %>%
  mutate(cum_non_na_start = cumsum(!is.na(!!sym(dv)))) %>%
  filter(cum_non_na_start > 0) %>%
  select(-cum_non_na_start) %>%
  ungroup() %>%
  arrange(laestab, time_period)

# Identify schools that do not have gaps at the end of the timeseries
list_laestab <- df %>%
  group_by(laestab) %>%
  # sort ascending by timeseries - END
  arrange(desc(time_period)) %>%
  mutate(cum_non_na_end = cumsum(!is.na(!!sym(dv)))) %>%
  # check if there are any per laestab
  summarise(
    n = n(),
    cum_non_na_end = sum(cum_non_na_end > 0)
  ) %>%
  # remove if so
  filter(n == cum_non_na_end) %>%
  pull(laestab) %>%
  unique()

# Remove any schools with gaps in their timeseries (i.e., NA in the middle of their data)
df <- df %>%
  filter(laestab %in% list_laestab) %>%
  group_by(laestab) %>%
  mutate(na = sum(is.na(!!sym(dv)))) %>%
  ungroup() %>%
  filter(na == 0) %>%
  select(-na)

# Update list of schools to include only those that don't have any missing values in the middle or at the end
list_laestab <- unique(df$laestab)


# Remove rows for years for which there is no outcome data, 
# and add observation count and count of outliers per school

# Perform the data transformation and filtering
df <- df %>%
  filter(laestab %in% list_laestab) %>%
  # Filter out rows where the variable of interest (dv) is NA
  filter(!is.na(get(dv))) %>%
  # Group the data by school identifier
  group_by(laestab) %>%
  # Add new columns to count non-NA observations and outliers within each group
  mutate(
    obs_count_dv = sum(!is.na(get(dv))), # Count the number of non-NA observations for dv
    outliers_dv = is_outlier_3sd(get(dv)),
    count_outliers_dv = sum(is_outlier_3sd(get(dv))) # Count the number of outliers for dv
  ) %>%
  # Remove the grouping to perform subsequent operations on the entire data frame
  ungroup() %>%
  # Filter out groups (schools) with fewer than 6 observations for dv
  filter(obs_count_dv >= 6) %>%
  # Filter out groups (schools) that have any outliers within their timeseries for dv
  filter(count_outliers_dv == 0) %>%
  # Select the columns to keep in the final output
  select(-c(count_outliers_dv, outliers_dv, count_outliers_dv, obs_count_dv)) %>%
  # Convert the resulting tibble back to a base R data frame
  as.data.frame()


# Remove outliers from data - 1st run #

df <- df %>%
  # Add a new column to identify outliers based on the 3-sigma rule
  mutate(
    outlier_dv = is_outlier_3sd(get(dv))
  ) %>%
  # Group the data by the 'laestab' column (likely a school identifier)
  group_by(laestab) %>%
  # Add a new column to count the number of outliers within each group
  mutate(
    count_outliers_dv = sum(outlier_dv)
  ) %>%
  # Remove the grouping to perform subsequent operations on the entire data frame
  ungroup() %>%
  # Filter out groups (schools) that have any outliers within their timeseries for dv
  filter(count_outliers_dv == 0) %>%
  # remove the temporary columns 'outlier_dv' and 'count_outliers_dv'
  select(-outlier_dv, -count_outliers_dv) %>%
  # Convert the resulting tibble back to a base R data frame
  as.data.frame()

if (is_outlier_3sd(df[, dv], show.bounds = T)[1] < 0) {
  # Remove outliers from data - 2nd run #
  # second run applied because first run resulted in such high SD that the lower bound was negative - which is implausible as a cut-off given that the PTR values are positive 
  
  df <- df %>%
    # Add a new column to identify outliers based on the 3-sigma rule
    mutate(
      outlier_dv = is_outlier_3sd(get(dv))
    ) %>%
    # Group the data by the 'laestab' column (likely a school identifier)
    group_by(laestab) %>%
    # Add a new column to count the number of outliers within each group
    mutate(
      count_outliers_dv = sum(outlier_dv)
    ) %>%
    # Remove the grouping to perform subsequent operations on the entire data frame
    ungroup() %>%
    # Filter out groups (schools) that have any outliers within their timeseries for dv
    filter(count_outliers_dv == 0) %>%
    # remove the temporary columns 'outlier_dv' and 'count_outliers_dv'
    select(-outlier_dv, -count_outliers_dv) %>%
    # Convert the resulting tibble back to a base R data frame
    as.data.frame()
}

# compute timeseries descriptives
desc <- df %>%
  group_by(laestab) %>%
  summarise(
    mean = mean(pupil_to_qual_teacher_ratio, na.rm = T),
    sd = sd(pupil_to_qual_teacher_ratio, na.rm = T),
    var = var(pupil_to_qual_teacher_ratio, na.rm = T),
    min = min(pupil_to_qual_teacher_ratio, na.rm = T),
    max = max(pupil_to_qual_teacher_ratio, na.rm = T),
    n = n()
  )

# Calculate pooled variance
# Sum the product of the number of observations minus one and the variance for each school, then divide by the total number of observations minus one.
pooled_variance <- sum((desc$n - 1) * desc$var) / sum(desc$n - 1)
pooled_sd <- sqrt(pooled_variance)

# Compute the weighted mean
# Multiply each school's mean by the number of observations for that school, sum these products, and then divide by the total number of observations.
pooled_mean <- sum(desc$n * desc$mean) / sum(desc$n)

# extract range as mean +/- 3SD -> for plotting
bound_lo <- pooled_mean - 3*pooled_sd
bound_up <- pooled_mean + 3*pooled_sd
```

```{r ratio, include=F}
# Function to calculate number of teachers based on pupil-to-teacher ratio
calculate_teachers <- function(pupil_teacher_ratio, num_pupils) {
  num_teachers <- num_pupils / pupil_teacher_ratio
  return(num_teachers)
}

# Function to calculate change in number of teachers based on change in ratio
calculate_change_in_teachers <- function(starting_ratio, change_in_ratio, num_pupils) {
  new_ratio <- starting_ratio + change_in_ratio
  initial_teachers <- num_pupils / starting_ratio
  new_teachers <- num_pupils / new_ratio
  change_in_teachers <- new_teachers - initial_teachers
  return(change_in_teachers)
}

# Number of pupils (constant)
num_pupils <- 1000
num_teach <- 62

# Starting ratio
starting_ratio <- num_pupils/num_teach

# Create a sequence of ratios from starting_ratio, incrementing by 0.2
ratios <- seq(starting_ratio - 3, starting_ratio + 3, by = 0.5)

# Calculate number of teachers for each ratio
teachers_needed <- sapply(ratios, calculate_teachers, num_pupils)

# Calculate number of teachers for each ratio
teachers_needed <- sapply(ratios, calculate_teachers, num_pupils)

# Create a data frame for better readability
results <- data.frame(
  ratio = ratios,
  teacher_fte = teachers_needed
)
results$change_ratio <- results$ratio - starting_ratio
results$change_fte <- results$teacher_fte - num_teach

# add to markdown
kbl(results, digits = 3, row.names = F, caption = "Mapping between changes in ratio and teacher FTE") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>%
  add_footnote("We here assume a constant number of pupil FTE of 1000.") %>%
  print()

# Example initial ratio and change in ratio
change_in_ratio <- -0.2

# Calculate change in number of teachers
change_in_teachers <- calculate_change_in_teachers(starting_ratio, change_in_ratio, num_pupils)

# # SECONDARY
# # Number of pupils (constant)
# num_pupils <- 1000
# starting_ratio <- 17.44
# num_teach <- num_pupils / starting_ratio
# 
# # determine percentage vector
# out <- data.frame(change_perc = seq(-.1, .1, 0.01))
# 
# # translate percentage into ratio
# out$effect_ratio <- out$change_perc * starting_ratio
# out$abs_ratio <- starting_ratio + out$effect_ratio
# out$effect_pooled_sd <- out$effect_ratio / pooled_sd
# 
# out$abs_teacher <- sapply(out$abs_ratio, calculate_teachers, num_pupils)
# out$effect_teacher <- out$abs_teacher - num_teach

```

```{r est, eval=FALSE, include=F}
# load in simulated data # 

# determine input filename
file_name <- file.path(dir, "02_scm", "interim", paste0("08_treated_schools_simulate_data_", gsub(" ", "_", id_name), ".csv"))

# read in results
df_sim_raw <- read.csv(file_name)
lookup <- unique(df_sim_raw[, c("time_period", "time_period_str")])

# Define timeseries
period.simulated <- unique(df_sim_raw$time_period[is.na(df_sim_raw$pupil_to_qual_teacher_ratio)]) # identify simulated years
period.post <- period.simulated # Simulated post-treatment period
period.avail <- sort(unique(df_sim_raw$time_period))
period.pre <- setdiff(period.avail, period.post) # Pre-treatment period

# determine ids of control schools
id_cont <- unique(df_sim_raw$laestab[df_sim_raw$laestab != id_treated])

unit.tr <- id_treated # Treated unit (in terms of id.var)
unit.co <- id_cont # Donors pool

# determine features and covariate adjustment settings
features <- params$features
cov.adj<- params$cov.adj

if (grepl("St Peter's", id_name)) s = 2 else s = 1 # use first simulation for now

# create copy to simulate interventions
df_sim_int <- df_sim_raw %>%
  # only focus on one simulation
  mutate(sim = get(paste0("sim_", s))) %>%
  select(c(laestab, time_period, time_period_str, school, 
           pupil_to_qual_teacher_ratio, fte_avg_age, pnpupfsm_e,
           sim)) %>%
  arrange(laestab, time_period) %>%
  as.data.frame()

if(apply_effects){
  
  # determine multiplier
  decrease = increments[k]      
  multiplier <- 1 - decrease
  
  df_sim_int <- df_sim_int %>%
    # Apply decrease
    mutate(sim_eff = ifelse(laestab == id_treated, sim*multiplier, sim)) %>%
    # replace NAs with simulated values
    mutate(pupil_to_qual_teacher_ratio = ifelse(is.na(pupil_to_qual_teacher_ratio), sim_eff, pupil_to_qual_teacher_ratio)) %>%
    arrange(laestab, time_period) %>%
    as.data.frame()
  
    # print treated unit and donor pool timeseries #
  
  # select columns
  tmp <- df_sim_int[, c("laestab", "time_period", "time_period_str", "school", "pupil_to_qual_teacher_ratio")]
  
  # create data
  tmp <- tmp %>%
    mutate(status = ifelse(laestab == paste(id_treated), id_name, "Donor schools")) %>%
    tidyr::pivot_longer(
      cols = -c(laestab, school, time_period, time_period_str, status),
      names_to = "variable") %>%
    mutate(variable = case_match(variable, 
                                 "pupil_to_qual_teacher_ratio" ~ "Outcome",
                                 "fte_avg_age" ~ "Teacher age",
                                 "pnpupfsm_e" ~ "% pupils FSM"
    ))
  tmp$variable <- factor(tmp$variable, levels = c("Outcome", "% pupils FSM", "Teacher age"))
  
  # plot timeseries average for each school
  cols <- c(navy40, coral)
  names(cols) <- c("Donor schools", id_name)
  
  ymin = min(bound_lo, min(tmp$value))
  ymax = max(bound_up, max(tmp$value))

  
  print(ggplot(data = tmp, aes(x = time_period, y = value, col = status, group = laestab)) +
          geom_line(data = tmp[tmp$status == "Donor schools", ], aes(col = paste("Donor schools"))) + 
          geom_vline(xintercept = period.pre[length(period.pre)]+0.5, linetype = "dotted") +
          geom_line(data = tmp[tmp$status == paste(id_name), ], aes(col = paste(id_name)), linewidth =.8) +
          facet_wrap(~ variable, ncol = 1, strip.position = "top", scales = "free_y") +
          ambition_theme +
          scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str) +
          coord_cartesian(ylim = c(ymin, ymax)) +
          scale_color_manual(
            breaks=c(id_name, "Donor schools"),
            values=cols) +
          ylab("Reported value") + xlab("Academic year") +
          theme(axis.text.x = element_text(angle = 45, hjust = 1),
                axis.title.x = element_blank(), 
                legend.title = element_blank()))
  cat("\n\n")

}


####################################
### Data preparation
scdata.out <- scdata(df = df_sim_int, 
                     id.var = id.var, 
                     time.var = time.var,
                     outcome.var = outcome.var,
                     period.pre = period.pre,
                     period.post = period.post,
                     unit.tr = unit.tr,
                     unit.co = unit.co,
                     features = features,
                     cov.adj = cov.adj)

####################################
### SC - point estimation with simplex
scest.out <- scest(data = scdata.out, 
                   w.constr = w.constr
)


# plot timeseries
if(apply_effects){
  # include pre and post data
  data.sc <- data.frame(time_period = c(period.pre, period.post), 
                      treated = c(scest.out$data$Y.pre, scest.out$data$Y.post),
                      synth = c(scest.out$est.results$Y.pre.fit, scest.out$est.results$Y.post.fit),
                      variable = "Outcome")
} else {
  # include pre data only
  data.sc <- data.frame(time_period = c(period.pre), 
                      treated = c(scest.out$data$Y.pre),
                      synth = c(scest.out$est.results$Y.pre.fit),
                      variable = "Outcome")
}

# plot treated and synthetic school
cols <- c(navy, coral)
names(cols) <- c("Synthetic school", id_name)

ymin = min(bound_lo, min(data.sc$treated), min(data.sc$synth))
ymax = max(bound_up, max(data.sc$treated), max(data.sc$synth))

plt <- ggplot(data = data.sc) +
  geom_line(aes(x = time_period, y = treated, col = paste(id_name))) +
  geom_point(aes(x = time_period, y = treated, col = paste(id_name))) +
  geom_line(aes(x = time_period, y = synth, col = "Synthetic school")) +
  geom_point(aes(x = time_period, y = synth, col = "Synthetic school")) +
  geom_vline(xintercept = period.pre[length(period.pre)]+0.5, linetype = "dotted") +
  facet_wrap(~ variable, ncol = 1, strip.position = "top", scales = "free_y") +
  ambition_theme +
  scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str) +
  coord_cartesian(ylim = c(ymin, ymax)) +
  scale_color_manual(
    breaks=c(id_name, "Synthetic school"),
    values=cols) +
  ylab("Reported value") + xlab("Academic year") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.title = element_blank())
print(plt)
cat("\n\n")

cat("\n\n")

```

```{r res, eval=FALSE, include=F}
#### SC - evaluate results ####
summarise_scest(scest.out, id_treated = id_treated, id_name = id_name, cv = F)

#### EXTRACT DATA #####

# Access and examine the raw features for the treated unit (A)
# Each row represents a different feature-year combination for the treated unit.
treated_features <- scest.out$data$A

# Access and examine the raw features for the control units (B)
# Each row represents a different feature-year combination for the control units, and each column represents a different control unit.
control_features <- scest.out$data$B

# Access and examine the synthetic control weights (w)
# Each element represents the weight assigned to a corresponding control unit in constructing the synthetic control.
weights <- scest.out$est.results$w

# Compute the synthetic control's pre-treatment feature values
synthetic_features_raw <- control_features %*% weights # this is a hypothetical scenario where we only take the weights into consideration

# Compare the treated and synthetic control feature values
comparison_raw <- cbind(treated_features, synthetic_features_raw)
colnames(comparison_raw) <- c(id_name, "Synthetic school")
comparison_raw <- as.data.frame(comparison_raw)
comparison_raw$Variable <- row.names(comparison_raw)
comparison_raw$Year <- as.numeric(stringi::stri_extract_last_regex(comparison_raw$Variable, "\\d{4}"))
comparison_raw$Variable <- gsub("[[:digit:]]+", "", comparison_raw$Variable)
comparison_raw$Variable <- gsub(".", "", comparison_raw$Variable, fixed = T)

# Make data long for plotting
comparison_raw <- reshape2::melt(comparison_raw, id.var = c("Variable", "Year"), value.name = "Value", variable.name = "Unit")
comparison_raw$Variable <- factor(comparison_raw$Variable,
                                  levels = c("pupil_to_qual_teacher_ratio", "fte_avg_age", "pnpupfsm_e"),
                                  labels = c("Outcome", "Teacher age", "% pupils FSM"))

# Plot the feature values
cols <- c(navy, coral)
names(cols) <- c("Synthetic school", id_name)

print(ggplot(data = comparison_raw, aes(x = Year, y = Value, group = Unit)) +
        geom_line(data = comparison_raw[comparison_raw$Unit == id_name, ], aes(col = paste(id_name))) +
        geom_point(data = comparison_raw[comparison_raw$Unit == id_name, ], aes(col = paste(id_name))) +
        geom_line(data = comparison_raw[comparison_raw$Unit == "Synthetic school", ], aes(col = "Synthetic school")) +
        geom_point(data = comparison_raw[comparison_raw$Unit == "Synthetic school", ], aes(col = "Synthetic school")) +
        facet_wrap(vars(Variable), ncol = 1, scales = "free_y") +
        labs(title = "Feature timeseries without covariate adjustment",
             x = "Academic year",
             y = "Reported value") +
        ambition_theme +
        theme(axis.text.x = element_text(angle = 45, hjust = 1),
              legend.title = element_blank(),
              strip.text = element_text(size = 10)) +
        scale_color_manual(
          breaks=c(id_name, "Synthetic school"),
          values=cols) +
        scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str)
)

if (!is.null(scest.out$data$C)) {
  
  # Access and examine the raw features for the control units (B) **and the covariates (C)**
  # Each row represents a different feature-year combination for the control units, and each column represents a different control unit.
  control_features <- cbind(scest.out$data$B, scdata.out$C)
  
  # Access and examine matrix *b*, containing the synthetic control weights (w) and values of the covariate adjustment (r)
  b <- scest.out$est.results$b # a matrix containing w (a matrix containing the estimated weights of the donors) and r (a matrix containing the values of the covariates used for adjustment)
  
  # Compute the synthetic control's pre-treatment feature values
  synthetic_features_adjusted <- control_features %*% b # this is how scest.out$est.results$A.hat is internally computed
  
  # Compare the treated and synthetic control feature values
  comparison_adjusted <- cbind(treated_features, synthetic_features_adjusted)
  colnames(comparison_adjusted) <- c(id_name, "Synthetic school")
  comparison_adjusted <- as.data.frame(comparison_adjusted)
  comparison_adjusted$Variable <- row.names(comparison_adjusted)
  comparison_adjusted$Year <- as.numeric(stringi::stri_extract_last_regex(comparison_adjusted$Variable, "\\d{4}"))
  comparison_adjusted$Variable <- gsub("[[:digit:]]+", "", comparison_adjusted$Variable)
  comparison_adjusted$Variable <- gsub(".", "", comparison_adjusted$Variable, fixed = T)
  
  # Make data long for plotting
  comparison_adjusted <- reshape2::melt(comparison_adjusted, id.var = c("Variable", "Year"), value.name = "Value", variable.name = "Unit")
  comparison_adjusted$Variable <- factor(comparison_adjusted$Variable,
                                         levels = c("pupil_to_qual_teacher_ratio", "fte_avg_age", "pnpupfsm_e"),
                                         labels = c("Outcome", "Teacher age", "% pupils FSM"))
  
  # Plot the feature values
  print(ggplot(data = comparison_adjusted, aes(x = Year, y = Value, group = Unit)) +
          geom_line(data = comparison_adjusted[comparison_adjusted$Unit == id_name, ], aes(col = paste(id_name))) +
          geom_point(data = comparison_adjusted[comparison_adjusted$Unit == id_name, ], aes(col = paste(id_name))) +
          geom_line(data = comparison_adjusted[comparison_adjusted$Unit == "Synthetic school", ], aes(col = "Synthetic school")) +
          geom_point(data = comparison_adjusted[comparison_adjusted$Unit == "Synthetic school", ], aes(col = "Synthetic school")) +
          facet_wrap(vars(Variable), ncol = 1, scales = "free_y") +
          labs(title = "Feature timeseries with covariate adjustment",
               x = "Academic year",
               y = "Reported value") +
          ambition_theme +
          theme(axis.text.x = element_text(angle = 45, hjust = 1),
                legend.title = element_blank(),
                strip.text = element_text(size = 10)) +
          scale_color_manual(
            breaks=c(id_name, "Synthetic school"),
            values=cols) +
          scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str)
  )
  
}
cat("\n\n")



```

```{r placebo, eval=FALSE, include=F}
# determine input filename
file_name <- file.path(dir, "02_scm", "interim", paste0("09_treated_schools_scpi_perm_" , gsub(" ", "_", id_name), "_decrease_", sprintf("%.2f", decrease), "_sim_", sprintf("%03d", s), ".csv"))

# read in results
storegaps <- read.csv(file_name)
names(storegaps)[1] <- "time_period"
names(storegaps) <- gsub("X", "", names(storegaps))

# compute ratio of post-treatment RMSPE to pre-treatment RMSPE                                                  
rmspe <- function(x){sqrt(mean(x^2))}

preloss <- apply(storegaps[1:length(period.pre), -1], 2, rmspe)
postloss <- apply(storegaps[(1+length(period.pre)):(length(period.pre)+length(period.post)), -1], 2, rmspe)
ratio <- sort(postloss/preloss)
observed_statistic <- ratio[names(ratio) == id_treated]

# compute treatment effect
postgap <- apply(storegaps[(1+length(period.pre)):(length(period.pre)+length(period.post)), -1], 2, mean)
avg_gap_post <- postgap[names(postgap) == id_treated]

# combine permutation data into df
perm_results <- data.frame(laestab = names(preloss),
                           rmspe_pre = preloss,
                           rmspe_post = postloss,
                           ratio = postloss / preloss)

# identify ill-fitting placebo runs
perm_results$thresh5 <- perm_results$rmspe_pre < perm_results$rmspe_pre[perm_results$laestab == id_treated] * 5
n_ill <- sum(perm_results$thresh5 == F)

# determine cut-off values
cutoff_value <- quantile(perm_results$ratio, 0.95)
cutoff_thresh5 <- quantile(perm_results$ratio[perm_results$thresh5 == T], 0.95)

# compute probability
prob <- sum(perm_results$ratio >= observed_statistic) / length(perm_results$ratio)
prob_thresh5 <- sum(perm_results$ratio[perm_results$thresh5] >= observed_statistic) / sum(perm_results$thresh5)

# Plot the permutation test results
plt <- ggplot(perm_results, aes(x = ratio)) +
        geom_histogram(data = perm_results[perm_results$thresh5 == T, ], aes(x = ratio), fill = navy40, boundary = 0) +
        geom_vline(aes(xintercept = observed_statistic), colour = red, linetype = "dashed", linewidth = 1) +
        geom_vline(aes(xintercept = cutoff_value), colour = blue, linewidth = 1) +
        labs(title = "Permutation test results",
             x = "Ratio (post-period RMSPE / pre-period RMSPE)",
             y = "Frequency",
             caption = "red - observed ratio in the treated unit; blue - 5% cut-off.") +
        ambition_theme + theme(plot.caption = element_text(size = 8, face = "plain", hjust = 1))
if (n_ill > 0) {
  plt <- plt + 
    geom_histogram(data = perm_results[perm_results$thresh5 == F, ], aes(x = ratio), fill = navy, boundary = 0) +
    geom_vline(aes(xintercept = cutoff_thresh5), colour = purple, linetype = "dashed", linewidth = 1) +
    labs(caption = "red - observed ratio in the treated unit; blue - 5% cut-off; purple - 5% cut-off (excl. ill-fits).")
}
print(plt)
cat("\n\n")


# p value
cat("When assigning the intervention at random in the data, the probability of obtaining a post-period RMSPE / pre-period RMSPE ratio as large as the treated school's is ", round(prob, digits = 3), ".\n\n", sep = "")
if (n_ill > 0) {
  cat("After removing any ill-fitted placebo runs (N = " , n_ill, "), the probability is ", round(prob_thresh5, digits = 3), ".\n\n", sep = "")
  
}


# create df with all gaps
df_gaps <- as.data.frame(storegaps) %>%
  #mutate(time_period = as.numeric(row.names(.))) %>%
  select(time_period, everything()) %>%
  tidyr::pivot_longer(., cols = names(.)[-1], names_to = "laestab", values_to = "pupil_to_qual_teacher_ratio") %>%
  mutate(idx_treat = ifelse(laestab == id_treated, TRUE, FALSE),
         thresh5 = laestab %in% perm_results$laestab[perm_results$thresh5])

# plot placebo gaps
print(ggplot(data = df_gaps, aes(x = time_period, y = pupil_to_qual_teacher_ratio, group = laestab)) +
        geom_line(data = df_gaps[!df_gaps$idx_treat & df_gaps$thresh5, ], aes(col = "Donor schools")) +
        geom_line(data = df_gaps[!df_gaps$idx_treat & !df_gaps$thresh5, ], aes(col = "Donor schools (ill fitted)")) +
        geom_vline(xintercept = period.pre[length(period.pre)]+0.5, linetype = "dotted") +
        geom_hline(yintercept = 0, linetype = "dotted") +
        geom_line(data = df_gaps[df_gaps$idx_treat,], aes(col = "Treated school"), linewidth = .8) +
        ambition_theme +
        theme(strip.text = element_text(size = 10),
              axis.text.x = element_text(angle = 45, hjust = 1),
              legend.title = element_blank(),
              plot.caption = element_text(size = 8, face = "plain", hjust = 1)) +
        coord_cartesian(ylim = c(-5, 5)) +
        ylab("Gap in ratio of pupils to qualified teachers") + xlab ("Academic year") +
        scale_color_manual(
          breaks=c("Treated school", "Donor schools", "Donor schools (ill fitted)"),
          values=c("Donor schools" = navy40, "Donor schools (ill fitted)" = navy, "Treated school" = coral)) +
        scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str))
cat("\n\n")

# extract metrics #

# compute pre-timeseries stats
sd_pre <- sd(df_sim_int$pupil_to_qual_teacher_ratio[df_sim_int$laestab == id_treated & ! df_sim_int$time_period %in% period.simulated])

# compute simulated data stats
mean_pre <- mean(df_sim_int$sim[df_sim_int$laestab == id_treated & df_sim_int$time_period %in% period.simulated])
mean_eff <- mean(df_sim_int$sim_eff[df_sim_int$laestab == id_treated & df_sim_int$time_period %in% period.simulated])

# effect in absolute terms
eff_abs <- mean_pre - mean_eff

# effect in SD of pretreatment timeseries
eff_sd <- eff_abs / sd_pre

# effect in national SD
eff_pooled_sd <- eff_abs / pooled_sd
eff_gap_pooled_sd <- avg_gap_post / pooled_sd

# initialise df for results
out <- data.frame(
  laestab = id_treated,
  school = id_name,
  n_donors = ncol(storegaps)-1,
  reduction = decrease,
  sd_pre = sd_pre,
  mean_pre = mean_pre,
  mean_eff = mean_eff,
  eff_abs = eff_abs,
  eff_sd = eff_sd,
  eff_pooled_sd = eff_pooled_sd,
  eff_gap = avg_gap_post,
  eff_gap_pooled_sd = eff_gap_pooled_sd,
  export = paste(round(avg_gap_post, 2), "/", round(eff_gap_pooled_sd, 2)),
  rmspe_pre = perm_results$rmspe_pre[perm_results$laestab == id_treated],
  rmspe_post = perm_results$rmspe_post[perm_results$laestab == id_treated],
  rmspe_ratio = observed_statistic,
  prob_all = sum(perm_results$ratio >= observed_statistic) / length(ratio),
  prob_thresh5 = sum(perm_results$ratio[perm_results$thresh5] >= observed_statistic) / sum(perm_results$thresh5),
  n_ill = n_ill
)

if (decrease == 0) {
  df_out <- out
} else {
  df_out <- rbind(df_out, out)
}

```

```{r sims, eval=FALSE, include=F}
# compute ratio of post-treatment RMSPE To pre-treatment RMSPE                                                  
rmspe <- function(x){sqrt(mean(x^2))}

# Calculate directional gaps: Use only negative post-treatment gaps
# negative because we would predict that the treatment LOWERS the DV pupil-to-teacher ratio
directional_postrmspe <- function(unit_id) {
  post_gaps <- storegaps[(length(period.pre)+1):nrow(storegaps), unit_id]
  negative_gaps <- post_gaps[post_gaps < 0]  # Focus on negative deviations
  if(length(negative_gaps) == 0) return(0)   # Handle no negative gaps
  sqrt(mean(negative_gaps^2))                # RMSPE of negative gaps
}

# process data from placebo runs #

# determine file pattern
pattern = paste0("09_treated_schools_scpi_perm_", gsub(" ", "_", id_name), "_decrease_", sprintf("%.2f", decrease))

# list all files
files = sort(list.files(path = file.path(dir, "02_scm", "interim"), pattern = pattern, full.names = T))

if (length(files) > 0) {
  
  for (f in 1:length(files)) {
    
    file = files[f]
    
    file = files[f]
    
    # read in results
    storegaps <- read.csv(file)
    names(storegaps)[1] <- "time_period"
    names(storegaps) <- gsub("X", "", names(storegaps))
    
    # compute RMPSE for pre and post
    prermspe <- apply(storegaps[1:length(period.pre), -1], 2, rmspe)
    postrmspe <- apply(storegaps[(1+length(period.pre)):(length(period.pre)+length(period.post)), -1], 2, rmspe)
    # compute post to pre ratio
    ratio <- sort(postrmspe/prermspe)
    # determine ratio in treated unit
    observed_ratio <- ratio[names(ratio) == id_treated]
    # permutation distribution of ratios
    permutation_ratios <- c(ratio)  # Includes treated unit's ratio
    
    # compute directional rmspe values for post
    # this only takes into consideration the any negative deviations in the gap when computing the RMSPE
    postrmspe_neg <- sapply(colnames(storegaps)[-1], directional_postrmspe)
    # compute post to pre ratio using directional rmspe post values
    ratio_negative <- postrmspe_neg / prermspe  # Directional RMSPE ratio
    # determine ratio in treated unit
    observed_ratio_neg <- ratio_negative[names(ratio_negative) == id_treated]
    # permutation distribution of directional ratios
    permutation_ratios_neg <- ratio_negative  # Includes all units (treated + placebos)
    
    # compute treatment effect: mean post-treatment gap for treated unit
    postgap <- apply(storegaps[(1+length(period.pre)):(length(period.pre)+length(period.post)), -1], 2, mean)
    avg_gap_post <- postgap[names(postgap) == id_treated]
    
    # effect in national SD
    eff_gap_pooled_sd <- avg_gap_post / pooled_sd

    # combine permutation data into df
    perm_results <- data.frame(laestab = names(prermspe),
                               rmspe_pre = prermspe,
                               rmspe_post = postrmspe,
                               ratio = postrmspe / prermspe,
                               rmspe_post_neg = postrmspe_neg,
                               ratio_neg = postrmspe_neg / prermspe,
                               gap_post = postgap)
    
    # identify ill-fitting placebo runs
    fit_threshold <- perm_results$rmspe_pre[perm_results$laestab == id_treated] * 5
    perm_results$ill_fitted <- perm_results$rmspe_pre > fit_threshold
    n_ill <- sum(perm_results$ill_fitted == T)
    cutoff_value <- quantile(perm_results$ratio, 0.95, na.rm = T)
    cutoff_thresh5 <- quantile(perm_results$ratio[perm_results$ill_fitted == F], 0.95, na.rm = T)
    
    # compute two-sided p values
    prob_two_sided <- sum(perm_results$ratio >= observed_ratio) / length(perm_results$ratio)
    prob_two_sided_thresh5 <- sum(perm_results$ratio[perm_results$ill_fitted == F] >= observed_ratio) / sum(perm_results$ill_fitted == F)
    
    # determine if the p values are significant
    sig_two_sided <- prob_two_sided < .05
    sig_two_sided_thresh5 <- prob_two_sided_thresh5 < .05
    
    # compute one-sided p values
    prob_one_sided <- sum(perm_results$ratio_neg >= observed_ratio_neg) / length(perm_results$ratio_neg)
    prob_one_sided_thresh5 <- sum(perm_results$ratio_neg[perm_results$ill_fitted == F] >= observed_ratio_neg) / sum(perm_results$ill_fitted == F)
    
    # determine if the p values are significant
    sig_one_sided <- prob_one_sided < .05
    sig_one_sided_thresh5 <- prob_one_sided_thresh5 < .05
    
    # initialise df for results
    sim <- data.frame(
      laestab = id_treated,
      school = id_name,
      n_donors = ncol(storegaps)-1,
      reduction = decrease,
      file = file,
      sim = f,
      eff_gap = avg_gap_post,
      eff_gap_pooled_sd = eff_gap_pooled_sd,
      export = paste(round(avg_gap_post, 2), "/", round(eff_gap_pooled_sd, 2)),
      rmspe_pre = perm_results$rmspe_pre[perm_results$laestab == id_treated],
      rmspe_post = perm_results$rmspe_post[perm_results$laestab == id_treated],
      rmspe_ratio = perm_results$ratio[perm_results$laestab == id_treated],
      rmspe_post_neg = perm_results$rmspe_post_neg[perm_results$laestab == id_treated],
      rmspe_ratio_neg = perm_results$ratio_neg[perm_results$laestab == id_treated],
      n_ill = n_ill,
      prob_two_sided = prob_two_sided,
      sig_two_sided = sig_two_sided,
      prob_two_sided_thresh5 = prob_two_sided_thresh5,
      sig_two_sided_thresh5 = sig_two_sided_thresh5,
      prob_one_sided = prob_one_sided,
      sig_one_sided = sig_one_sided,
      prob_one_sided_thresh5 = prob_one_sided_thresh5,
      sig_one_sided_thresh5 = sig_one_sided_thresh5
    )
    
    if (f == 1 & decrease == 0) {
      df_sim <- sim
    } else {
      df_sim <- rbind(df_sim, sim)
    }
    
  }
  
}

```

```{r power, eval=FALSE, include=F}
# add decrease in percent
df_sim$decrease = factor(paste0(df_sim$reduction * 100, "%"), levels = paste0(0:10, "%"))

# get counts and power obtained across all simulations for this setting #
power <- df_sim %>% 
  group_by(decrease) %>% 
  summarise(
    n_ill = mean(n_ill),
    n_sig_two_sided = sum(sig_two_sided_thresh5),
    power_two_sided_num = 100 * sum(sig_two_sided_thresh5)/n(),
    power_two_sided = paste0(power_two_sided_num, "%"),
    n_sig_one_sided = sum(sig_two_sided_thresh5),
    power_one_sided_num = 100 * sum(sig_one_sided_thresh5)/n(),
    power_one_sided = paste0(power_one_sided_num, "%")
  )

row_idx <- which(power$power_one_sided_num >= 80) 
  
# compute descriptive stats
vars_to_check <- c("eff_gap", "eff_gap_pooled_sd", "rmspe_pre", "rmspe_post", "rmspe_ratio", "rmspe_post_neg", "rmspe_ratio_neg")

out <- 
  # compute descriptive stats
  rbind(
    do.call("rbind", psych::describeBy(df_sim[, vars_to_check], group = df_sim[, "decrease"]))
  ) %>%
  # add decrease and vars from row.names, round values and ensure that they all have two digits
  mutate(
    decrease = sub("%.*", "%", row.names(.)),
    vars = sub(".*%.", "", row.names(.)),
    across(where(is.numeric), ~ round(.x, digits = 2)),
    across(where(is.numeric), ~ sprintf("%.2f", .x))
  ) %>%
  # make decrease factor and create summary string
    mutate(
    decrease = factor(decrease, levels = paste0(0:10, "%")),
    vars = factor(vars, levels = vars_to_check),
    summary = paste0(mean, " (", sd, ") ", "[", min, ";", max, "]")
  ) %>%
  # drop vars and arrange columns
  select(vars, decrease, summary) %>%
  relocate(vars, decrease) %>%
  arrange(vars, decrease) %>%
  tibble::remove_rownames(.) %>%
  # make data wide
  tidyr::pivot_wider(names_from = vars, values_from = summary) %>%
  # merge with counts and power obtained
  as.data.frame()

# print to markdown
out <- full_join(power, out) %>%
  select(-c(power_two_sided_num, power_one_sided_num))

kbl(out, row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>%
  row_spec(row_idx, bold = T) %>%
  print()
  
# determine output filename
file_name <- file.path(dir, "02_scm", "interim", paste0(file_stem, "_TMP_" , gsub(" ", "_", id_name), ".csv"))
write.csv(out, file = file_name, row.names = FALSE)

# plot results of all simulations #

# faceted histogram - two sided test
plt <- ggplot(data = df_sim) +
  geom_histogram(aes(x = prob_two_sided_thresh5, fill = sig_two_sided_thresh5), binwidth = 0.01, boundary = 0, colour = "black", position = "identity") +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(axis.title.y = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_fill_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  xlab("p value (two-sided)") +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")
# faceted histogram - one sided test
plt <- ggplot(data = df_sim) +
  geom_histogram(aes(x = prob_one_sided_thresh5, fill = sig_one_sided_thresh5), binwidth = 0.01, boundary = 0, colour = "black", position = "identity") +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(axis.title.y = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_fill_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  xlab("p value (one-sided)") +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")

# scatter plot of probability and effect size - two sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_two_sided_thresh5, y = eff_gap, col = sig_two_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  ylab("Average treatment effect (treated - synth)") +
  xlab("p value (two-sided)") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")
# scatter plot of probability and effect size - one sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_one_sided_thresh5, y = eff_gap, col = sig_one_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  ylab("Average treatment effect (treated - synth)") +
  xlab("p value (one-sided)") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")

# scatter plot of probability and effect size - two sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_two_sided_thresh5, y = eff_gap/pooled_sd, col = sig_two_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "left") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral) + 
  xlab("p value (two-sided)") +
  scale_y_continuous(
    "Eff (abs) = mean(treated – synth)", 
    sec.axis = sec_axis(~ . / pooled_sd, name = "Eff (pooled SD) = Eff (abs) / pooled national SD ")
  )
print(plt)
cat("\n\n")
# scatter plot of probability and effect size - one sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_one_sided_thresh5, y = eff_gap/pooled_sd, col = sig_one_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "left") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral) + 
  xlab("p value (one-sided)") +
  scale_y_continuous(
    "Eff (abs) = mean(treated – synth)", 
    sec.axis = sec_axis(~ . / pooled_sd, name = "Eff (pooled SD) = Eff (abs) / pooled national SD ")
  )
print(plt)
cat("\n\n")

# scatter plot of probability and effect size - two sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_two_sided_thresh5, y = eff_gap/pooled_sd, col = sig_two_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "left") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral) + 
  xlab("p value (two-sided)") +
  scale_y_continuous(
    paste0("Change in ratio where 0 equals ", round(starting_ratio, 2)), 
    sec.axis = sec_axis(~ calculate_change_in_teachers(starting_ratio, ., num_pupils), name = paste0("Change in teacher FTE where 0 equals ", round(num_teach, 2)))
  )
print(plt)
cat("\n\n")
# scatter plot of probability and effect size - one sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_one_sided_thresh5, y = eff_gap/pooled_sd, col = sig_one_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "left") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral) + 
  xlab("p value (one-sided)") +
  scale_y_continuous(
    paste0("Change in ratio where 0 equals ", round(starting_ratio, 2)), 
    sec.axis = sec_axis(~ calculate_change_in_teachers(starting_ratio, ., num_pupils), name = paste0("Change in teacher FTE where 0 equals ", round(num_teach, 2)))
  )
print(plt)
cat("\n\n")

# scatter plot of probability and ratio - two sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_two_sided_thresh5, y = rmspe_ratio, col = sig_two_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  ylab("Ratio of RMSPE (post) to RMSPE (pre)") +
  xlab("p value (two-sided)") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")
# scatter plot of probability and ratio - one sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_one_sided_thresh5, y = rmspe_ratio_neg, col = sig_one_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  xlab("p value (one-sided)") +
  ylab("Ratio of RMSPE (post negative) to RMSPE (pre)") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")

# determine output filename
file_name <- file.path(dir, "02_scm", "interim", paste0(file_stem, "_" , gsub(" ", "_", id_name), ".csv"))
# df_sim <- read.csv(file_name)
# save output
write.csv(df_sim, file = file_name, row.names = FALSE)


swf %>% filter(laestab == id_treated) %>%  
  select(time_period, pupils_fte, qualified_teachers_fte, pupil_to_qual_teacher_ratio) %>%
  mutate(ratio_change = pupil_to_qual_teacher_ratio - lag(pupil_to_qual_teacher_ratio, default = pupil_to_qual_teacher_ratio[1]),
         teacher_fte_change = qualified_teachers_fte - lag(qualified_teachers_fte, default = qualified_teachers_fte[1])) %>%
  kbl(row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>%
  print()

```


```{r run_code, echo=F, message=FALSE, results='asis', fig.align='center', fig.height=6, fig.width=8, out.width='100%', out.height='100%'}

#### Define best parameter settings from grid search - per school ####
info <- list(
  # St Peters
  list(school = "St Peter's Catholic School",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("constant")),
       region.filter = "same",
       sd.range = NULL,
       decrease_sim = c(seq(.00, .1, 0.01))),
       # decrease_sim = c(seq(.00, .1, 0.02))),
  # Dixon Music primary
  list(school = "Dixons Music Primary",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("constant")),
       region.filter = "same",
       sd.range = 50),
  # Marchbank Primary
  list(school = "Dixons Marchbank Primary",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("constant")),
       region.filter = "same",
       sd.range = 50,
       decrease_sim = c(seq(.00, .1, 0.02))),
  # Manningham Academy
  list(school = "Dixons Manningham Academy",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("trend")),
       region.filter = "same",
       sd.range = 50,
       decrease_sim = c(seq(.00, .1, 0.02))),
  # Kings Academy
  list(school = "Dixons Kings Academy",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("constant")),
       region.filter = "same",
       sd.range = NULL),
  # Dixons Trinity Academy
  list(school = "Dixons Trinity Academy",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("constant")),
       region.filter = "same",
       sd.range = NULL),
  # McMillan Academy
  list(school = "Dixons McMillan Academy",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = NULL,
       region.filter = "same",
       sd.range = NULL),
  # Cottingley Academy
  list(school = "Dixons Cottingley Academy",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("trend")),
       region.filter = "same",
       sd.range = NULL),
  # City Academy
  list(school = "Dixons City Academy",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("constant")),
       region.filter = c("same","neighbouring"),
       sd.range = 100,
       decrease_sim = c(seq(.00, .1, 0.02))),
  # Dixons Unity Academy
  list(school = "Dixons Unity Academy",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("constant")),
       region.filter = "same",
       sd.range = NULL),
  # Highcrest Academy
  list(school = "The Highcrest Academy",
       features = c("pupil_to_qual_teacher_ratio", "pnpupfsm_e", "fte_avg_age"),
       cov.adj = list(c("constant")),
       region.filter = c("same","neighbouring"),
       sd.range = 100)
)
info <- info[c(1, 3, 4, 9)] # focus on St. Peters, Marchbank Primary, Manningham Academy and City for now
# info <- info[c(1)] # focus on St. Peters, Marchbank Primary, Manningham Academy and City for now

#### Process data #####

# Set options for data preparation
id.var <- "laestab" # ID variable
time.var <- "time_period" # Time variable
outcome.var <- "pupil_to_qual_teacher_ratio" # Dependent variable

w.constr <- list(name = "simplex") # use canonical SC


# specify increments for decrease
increments <- seq(.00, .1, 0.01)
i = 1
#### run loop ####
for (i in 1:length(info)) {
  
  # get best parameter for given school
  # i = 3 # debug
  params <- info[[i]]
  
  # define id_treated
  id_name <- params$school
  id_treated <- df_region$laestab[df_region$school == id_name]
  
  # process data
  df <- process_data_scm(id_treated = id_treated)
  
  
  cat("# ", id_name, "\n\n")
  
  # print some information about the school
  cat("Type of establishment:", est_treated$typeofestablishment_name, "\n\n")
  cat("Phase:", est_treated$phaseofeducation_name, "\n\n")
  cat("Gender of pupils:", est_treated$gender_name, "\n\n")
  cat("Religious character:", est_treated$religiouscharacter_name, "\n\n")
  cat("Trust flag:", est_treated$trustschoolflag_name, "\n\n")
  cat("Local authority:", est_treated$la_name, "\n\n")
  cat("Region:", est_treated$gor_name, "\n\n")
  
  # prepare data and estimate scm
  cat("## SCM for pre-treatment data \n\n")
  apply_effects <- FALSE
  <<est>>
    # inspect results
    <<res>> 
    
    # show output
    cat("## SCM for simulated data \n\n")
  
  
  for (k in 1:length(increments)) {
    
    decrease = increments[k]
    
    # run grid search
    cat("### ", decrease * 100, "% decrease in ratio \n\n")
    # prepare data and estimate scm
    apply_effects <- TRUE
    <<est>>
        
        # permutation testing
        <<placebo>>
      
      # process all simulations
      if(decrease %in% params$decrease_sim) {
        <<sims>>
      }
    }
  
  # show outputc
  cat("## Power analysis \n\n")
  # result of power simulations
  <<power>>

}

```