---
title: "Power analysis with *scpi* package"
author: "Stefanie Meliss"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    self_contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen = 999)
# empty work space
rm(list = ls())
gc()

# Set seed
set.seed(202324)

# load libraries
library(kableExtra)
library(dplyr)
library(data.table)
library(ggplot2)
library(scpi)

# create function to source code
source_code <- function(root_dir_name = "code", target_repo = "helper_functions", branch = "main", file_name = "file.R") {
  
  # construct URL
  git_url <- paste0("https://raw.githubusercontent.com/stefaniemeliss/", target_repo, "/", branch, "/", file_name)
  
  # attempt to download from github
  tempp_file <- tempfile(fileext = ".R")
  
  # run processing with the parameters
  message <- tryCatch({
    curl::curl_download(git_url, tempp_file, quiet = F)
  }, error = function(e) {
    return(error = paste("Error in curl::curl_download:", e$message))
  })

  if(!grepl("Error", message)) {
    
    # if successful, source file
    source(tempp_file)
    remove(tempp_file)
    
  } else { # load local copy of file
    
    # Get the current working directory
    current_dir <- getwd()
    
    # Split the current directory into its components
    dir_components <- strsplit(current_dir, "/")[[1]]
    
    # Identify the root directory dynamically based on the provided root directory name
    root_index <- which(dir_components == root_dir_name)
    if (length(root_index) == 0) {
      stop(paste("Root directory", root_dir_name, "not found in the current path"))
    }
    root_dir <- do.call(file.path, as.list(dir_components[1:root_index]))
    
    # Identify the subdirectory one level below the root and construct its absolute path
    project_repo <- dir_components[root_index + 1]
    dir <- file.path(root_dir, project_repo)
    
    if (target_repo != project_repo) {
      dir <- gsub(project_repo, target_repo, dir) 
    }
    
    # Construct the full file path
    file_path <- file.path(dir, file_name)
    
    # Print the directory and file path for debugging
    print(paste("Directory:", dir))
    print(paste("File path:", file_path))
    
    # Source the file into the parent frame
    source(file_path, local = parent.frame())
  }
}

# source functions
source_code(target_repo = "scm_feasibility", file_name = "functions.R")

# Define the base directory
dir <- get_directory()
dir_data <- file.path(dir, "data")
dir_misc <- file.path(dir, "misc")

# get file stem name
file_stem <- get_file_stem()

# copy data #
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_swf.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_pupils.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_search.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_groups.csv"), dir_data, overwrite = T)

# load data #

swf <- fread(file.path(dir_data, "data_swf.csv"))
pup <- fread(file.path(dir_data, "data_pupils.csv"))
est <- fread(file.path(dir_data, "data_establishments_search.csv"), na.strings = "")
groups <- fread(file.path(dir_data, "data_establishments_groups.csv"), na.strings = "")

uid_treated <- 2939

# Dixon schools
dix <- groups %>% filter(group_uid == uid_treated)

# get establishment data from treated schools
list_laestab <- c(dix$laestab)

# create lookup 
lookup <- data.frame(time_period = sort(unique(swf$time_period)))
lookup$time_period_str <- insert_slash(lookup$time_period)
lookup$time_period <- as.numeric(substr(lookup$time_period, 0, 4))


# Create the data frame
lookup <- data.frame(time_period = c(2010:2026), 
                     time_period_str = c("2010/11", "2011/12", "2012/13", "2013/14", "2014/15", "2015/16", 
                                         "2016/17", "2017/18", "2018/19", "2019/20", "2020/21", "2021/22", 
                                         "2022/23", "2023/24", "2024/25", "2025/26", "2026/27"))


```


```{r nat, include=F}
dv <- "pupil_to_qual_teacher_ratio"

# determine laestabs currently open
list_laestab <- est %>%
  filter(grepl("Open", establishmentstatus_name)) %>%
  filter(grepl("ary|All", phaseofeducation_name)) %>%
  pull(laestab) %>%
  unique()

# Perform the data transformation and filtering
z <- swf %>%
  filter(laestab %in% list_laestab) %>%
  # Select relevant columns from the data frame
  select(time_period, laestab, school, urn, !!sym(dv))

# Add MAT information to the dataset
# Create lookup table with relevant group information (avoiding duplicates)
lookup <- est[grepl("Open", establishmentstatus_name) & laestab %in% list_laestab, c("laestab", "establishmentname", "gor_name", "phaseofeducation_name", "opendate")]
lookup <- lookup[!duplicated(lookup), ]
df <- merge(z, lookup, by = "laestab", all.x = T)

# ---- Longitudinal data filtering ----

# Remove any NA years at the beginning of the timeseries
# Create a cumulative sum of non-NA values starting from the first non-NA value encountered.
# cum_non_na remain zero as long as the values are NAs
df <- df %>%
  group_by(laestab) %>%
  # sort ascending by timeseries - BEGINNING
  arrange(time_period) %>%
  mutate(cum_non_na_start = cumsum(!is.na(!!sym(dv)))) %>%
  filter(cum_non_na_start > 0) %>%
  select(-cum_non_na_start) %>%
  ungroup() %>%
  arrange(laestab, time_period)

# Identify schools that do not have gaps at the end of the timeseries
list_laestab <- df %>%
  group_by(laestab) %>%
  # sort ascending by timeseries - END
  arrange(desc(time_period)) %>%
  mutate(cum_non_na_end = cumsum(!is.na(!!sym(dv)))) %>%
  # check if there are any per laestab
  summarise(
    n = n(),
    cum_non_na_end = sum(cum_non_na_end > 0)
  ) %>%
  # remove if so
  filter(n == cum_non_na_end) %>%
  pull(laestab) %>%
  unique()

# Remove any schools with gaps in their timeseries (i.e., NA in the middle of their data)
df <- df %>%
  filter(laestab %in% list_laestab) %>%
  group_by(laestab) %>%
  mutate(na = sum(is.na(!!sym(dv)))) %>%
  ungroup() %>%
  filter(na == 0) %>%
  select(-na)

# Update list of schools to include only those that don't have any missing values in the middle or at the end
list_laestab <- unique(df$laestab)


# Remove rows for years for which there is no outcome data, 
# and add observation count and count of outliers per school

# Perform the data transformation and filtering
df <- df %>%
  filter(laestab %in% list_laestab) %>%
  # Filter out rows where the variable of interest (dv) is NA
  filter(!is.na(get(dv))) %>%
  # Group the data by school identifier
  group_by(laestab) %>%
  # Add new columns to count non-NA observations and outliers within each group
  mutate(
    obs_count_dv = sum(!is.na(get(dv))), # Count the number of non-NA observations for dv
    outliers_dv = is_outlier_3sd(get(dv)),
    count_outliers_dv = sum(is_outlier_3sd(get(dv))) # Count the number of outliers for dv
  ) %>%
  # Remove the grouping to perform subsequent operations on the entire data frame
  ungroup() %>%
  # Filter out groups (schools) with fewer than 6 observations for dv
  filter(obs_count_dv >= 6) %>%
  # Filter out groups (schools) that have any outliers within their timeseries for dv
  filter(count_outliers_dv == 0) %>%
  # Select the columns to keep in the final output
  select(-c(count_outliers_dv, outliers_dv, count_outliers_dv, obs_count_dv)) %>%
  # Convert the resulting tibble back to a base R data frame
  as.data.frame()


# Remove outliers from data - 1st run #

df <- df %>%
  # Add a new column to identify outliers based on the 3-sigma rule
  mutate(
    outlier_dv = is_outlier_3sd(get(dv))
  ) %>%
  # Group the data by the 'laestab' column (likely a school identifier)
  group_by(laestab) %>%
  # Add a new column to count the number of outliers within each group
  mutate(
    count_outliers_dv = sum(outlier_dv)
  ) %>%
  # Remove the grouping to perform subsequent operations on the entire data frame
  ungroup() %>%
  # Filter out groups (schools) that have any outliers within their timeseries for dv
  filter(count_outliers_dv == 0) %>%
  # remove the temporary columns 'outlier_dv' and 'count_outliers_dv'
  select(-outlier_dv, -count_outliers_dv) %>%
  # Convert the resulting tibble back to a base R data frame
  as.data.frame()

if (is_outlier_3sd(df[, dv], show.bounds = T)[1] < 0) {
  # Remove outliers from data - 2nd run #
  # second run applied because first run resulted in such high SD that the lower bound was negative - which is implausible as a cut-off given that the PTR values are positive 
  
  df <- df %>%
    # Add a new column to identify outliers based on the 3-sigma rule
    mutate(
      outlier_dv = is_outlier_3sd(get(dv))
    ) %>%
    # Group the data by the 'laestab' column (likely a school identifier)
    group_by(laestab) %>%
    # Add a new column to count the number of outliers within each group
    mutate(
      count_outliers_dv = sum(outlier_dv)
    ) %>%
    # Remove the grouping to perform subsequent operations on the entire data frame
    ungroup() %>%
    # Filter out groups (schools) that have any outliers within their timeseries for dv
    filter(count_outliers_dv == 0) %>%
    # remove the temporary columns 'outlier_dv' and 'count_outliers_dv'
    select(-outlier_dv, -count_outliers_dv) %>%
    # Convert the resulting tibble back to a base R data frame
    as.data.frame()
}

# compute timeseries descriptives
desc <- df %>%
  group_by(laestab) %>%
  summarise(
    mean = mean(pupil_to_qual_teacher_ratio, na.rm = T),
    sd = sd(pupil_to_qual_teacher_ratio, na.rm = T),
    var = var(pupil_to_qual_teacher_ratio, na.rm = T),
    min = min(pupil_to_qual_teacher_ratio, na.rm = T),
    max = max(pupil_to_qual_teacher_ratio, na.rm = T),
    n = n()
  )

# Calculate pooled variance
# Sum the product of the number of observations minus one and the variance for each school, then divide by the total number of observations minus one.
pooled_variance <- sum((desc$n - 1) * desc$var) / sum(desc$n - 1)
pooled_sd <- sqrt(pooled_variance)

# Compute the weighted mean
# Multiply each school's mean by the number of observations for that school, sum these products, and then divide by the total number of observations.
pooled_mean <- sum(desc$n * desc$mean) / sum(desc$n)

# extract range as mean +/- 3SD -> for plotting
bound_lo <- pooled_mean - 3*pooled_sd
bound_up <- pooled_mean + 3*pooled_sd
```

```{r ratio, include=F}
# Function to calculate number of teachers based on pupil-to-teacher ratio
calculate_teachers <- function(pupil_teacher_ratio, num_pupils) {
  num_teachers <- num_pupils / pupil_teacher_ratio
  return(num_teachers)
}

# Function to calculate change in number of teachers based on change in ratio
calculate_change_in_teachers <- function(starting_ratio, change_in_ratio, num_pupils) {
  new_ratio <- starting_ratio + change_in_ratio
  initial_teachers <- num_pupils / starting_ratio
  new_teachers <- num_pupils / new_ratio
  change_in_teachers <- new_teachers - initial_teachers
  return(change_in_teachers)
}

# Number of pupils (constant)
num_pupils <- 1000
num_teach <- 62

# Starting ratio
starting_ratio <- num_pupils/num_teach

# Create a sequence of ratios from starting_ratio, incrementing by 0.2
ratios <- seq(starting_ratio - 3, starting_ratio + 3, by = 0.5)

# Calculate number of teachers for each ratio
teachers_needed <- sapply(ratios, calculate_teachers, num_pupils)

# Calculate number of teachers for each ratio
teachers_needed <- sapply(ratios, calculate_teachers, num_pupils)

# Create a data frame for better readability
results <- data.frame(
  ratio = ratios,
  teacher_fte = teachers_needed
)
results$change_ratio <- results$ratio - starting_ratio
results$change_fte <- results$teacher_fte - num_teach

# add to markdown
kbl(results, digits = 3, row.names = F, caption = "Mapping between changes in ratio and teacher FTE") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>%
  add_footnote("We here assume a constant number of pupil FTE of 1000.") %>%
  print()

# Example initial ratio and change in ratio
change_in_ratio <- -0.2

# Calculate change in number of teachers
change_in_teachers <- calculate_change_in_teachers(starting_ratio, change_in_ratio, num_pupils)

calculate_change_in_teachers(starting_ratio, 0.5, num_pupils)
calculate_change_in_teachers(starting_ratio, -0.5, num_pupils)

# ACADEMIES
# Number of pupils (constant)
num_pupils <- 1000
starting_ratio <- 18.63
num_teach <- num_pupils / starting_ratio

# determine percentage vector
out <- data.frame(change_perc = seq(-.1, .1, 0.01))

# translate percentage into ratio
out$effect_ratio <- out$change_perc * starting_ratio
out$abs_ratio <- starting_ratio + out$effect_ratio
out$effect_pooled_sd <- out$effect_ratio / pooled_sd

out$abs_teacher <- sapply(out$abs_ratio, calculate_teachers, num_pupils)
out$effect_teacher <- out$abs_teacher - num_teach

```


```{r est, eval=FALSE, include=F}
### ---- prepare data ---- ###

# load in simulated data #
# determine input filename
file_name <- file.path(dir, "03_scm_mat", "interim", paste0("06_treated_mat_simulate_data_", tolower(phase), "_it_", sprintf("%03d", ii), ".csv"))

# read in results
df_sim_raw <- read.csv(file_name)
lookup <- unique(df_sim_raw[, c("time_period", "time_period_str")])

# Define timeseries
period.simulated <- unique(df_sim_raw$time_period[is.na(df_sim_raw$pupil_to_qual_teacher_ratio)]) # identify simulated years
period.post <- period.simulated # Simulated post-treatment period
period.avail <- sort(unique(df_sim_raw$time_period))
period.pre <- setdiff(period.avail, period.post) # Pre-treatment period

# compute MAT level average
# df_avg <- df_sim_int %>% # APPLY EFFECTS AT SCHOOL LEVEL
df_avg_raw <- df_sim_raw %>% # APPLY EFFECTS AT MAT LEVEL
  group_by(group_uid, time_period)  %>%
  summarise(
    !!sym(dv) := mean(!!sym(dv)),
    !!sym(var_teach) := mean(!!sym(var_teach)),
    !!sym(var_pup) := mean(!!sym(var_pup)),
    sim = mean(sim_1),
    n = n(), .groups = "drop"
  ) %>% 
  ungroup() %>%
  left_join(lookup, .) %>%
  mutate(status = ifelse(group_uid == uid_treated, id_group, "Donor MATs")) %>%
  arrange(group_uid, time_period) %>%
  as.data.frame()

if (apply_effects) {
  multiplier <- 1 - decrease
  # APPLY EFFECTS AT SCHOOL LEVEL
  df_avg_int <- df_avg_raw %>%
    # Apply decrease
    mutate(sim_eff = ifelse(group_uid == uid_treated, sim*multiplier, sim)) %>%
    # replace NAs with simulated values
    mutate(!!sym(dv) := ifelse(is.na(!!sym(dv)), sim_eff, !!sym(dv))) %>%
    arrange(group_uid, time_period) %>%
    as.data.frame()
} else {
  df_avg_int <- df_avg_raw
}


# determine ids of control schools
id_cont <- unique(MATs$group_uid[MATs$group_uid != uid_treated])

unit.tr <- uid_treated # Treated unit (in terms of id.var)
unit.co <- id_cont # Donors pool

# determine features and covariate adjustment settings
features <- unlist(strsplit(params$features, ", "))
if(!is.na(params$cov.adj)){
  cov.adj <- case_match(params$cov.adj, "constant" ~ list(c("constant")), "trend" ~ list(c("trend")), "constant, trend" ~ list(c("constant", "trend")))
} else { 
  cov.adj <- NULL
}

####################################
### Data preparation
scdata.out <- scdata(df = df_avg_int, 
                     id.var = id.var, 
                     time.var = time.var,
                     outcome.var = outcome.var,
                     period.pre = period.pre,
                     period.post = period.post,
                     unit.tr = unit.tr,
                     unit.co = unit.co,
                     features = features,
                     cov.adj = cov.adj)

####################################
### SC - point estimation with simplex
scest.out <- scest(data = scdata.out, 
                   w.constr = w.constr
)


# plot treated and synthetic school
cols <- c(navy, coral)
names(cols) <- c("Synthetic MAT", id_group)

# plot timeseries
if(apply_effects){
  # include pre and post data
  data.sc <- data.frame(time_period = c(period.pre, period.post), 
                      treated = c(scest.out$data$Y.pre, scest.out$data$Y.post),
                      synth = c(scest.out$est.results$Y.pre.fit, scest.out$est.results$Y.post.fit),
                      variable = "Outcome")
} else {
  # include pre data only
  data.sc <- data.frame(time_period = c(period.pre), 
                      treated = c(scest.out$data$Y.pre),
                      synth = c(scest.out$est.results$Y.pre.fit),
                      variable = "Outcome")
}

ymin = min(bound_lo, min(data.sc$treated), min(data.sc$synth))
ymax = max(bound_up, max(data.sc$treated), max(data.sc$synth))

plt <- ggplot(data = data.sc) +
  geom_line(aes(x = time_period, y = treated, col = paste(id_group))) +
  geom_point(aes(x = time_period, y = treated, col = paste(id_group))) +
  geom_line(aes(x = time_period, y = synth, col = "Synthetic MAT")) +
  geom_point(aes(x = time_period, y = synth, col = "Synthetic MAT")) +
  geom_vline(xintercept = period.pre[length(period.pre)]+0.5, linetype = "dotted") +
  facet_wrap(~ variable, ncol = 1, strip.position = "top", scales = "free_y") +
  ambition_theme +
  scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str) +
  coord_cartesian(ylim = c(ymin, ymax)) +
  scale_color_manual(
    breaks=c(id_group, "Synthetic MAT"),
    values=cols) +
  ylab("Reported value") + xlab("Academic year") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.title = element_blank())
print(plt)
cat("\n\n")

cat("\n\n")

```

```{r res, eval=FALSE, include=F}
#### SC - evaluate results ####
summarise_scest(scest.out, id_treated = uid_treated, id_name = id_group, cv = F)

print(scplot(result = scest.out, plot.range = period.pre,
             label.xy = list(x.lab = "Start of academic year", y.lab = "Ratio of pupils to qualified teachers")))
cat("\n\n")
#### EXTRACT DATA #####

# Access and examine the raw features for the treated unit (A)
# Each row represents a different feature-year combination for the treated unit.
treated_features <- scest.out$data$A

# Access and examine the raw features for the control units (B)
# Each row represents a different feature-year combination for the control units, and each column represents a different control unit.
control_features <- scest.out$data$B

# Access and examine the synthetic control weights (w)
# Each element represents the weight assigned to a corresponding control unit in constructing the synthetic control.
weights <- scest.out$est.results$w

# Compute the synthetic control's pre-treatment feature values
synthetic_features_raw <- control_features %*% weights # this is a hypothetical scenario where we only take the weights into consideration

# Compare the treated and synthetic control feature values
comparison_raw <- cbind(treated_features, synthetic_features_raw)
colnames(comparison_raw) <- c(id_group, "Synthetic MAT")
comparison_raw <- as.data.frame(comparison_raw)
comparison_raw$Variable <- row.names(comparison_raw)
comparison_raw$Year <- as.numeric(stringi::stri_extract_last_regex(comparison_raw$Variable, "\\d{4}"))
comparison_raw$Variable <- gsub("[[:digit:]]+", "", comparison_raw$Variable)
comparison_raw$Variable <- gsub(".", "", comparison_raw$Variable, fixed = T)

# Make data long for plotting
comparison_raw <- reshape2::melt(comparison_raw, id.var = c("Variable", "Year"), value.name = "Value", variable.name = "Unit")
comparison_raw$Variable <- factor(comparison_raw$Variable,
                                  levels = c("pupil_to_qual_teacher_ratio", "fte_avg_age", "pnpupfsm_e"),
                                  labels = c("Outcome", "Teacher age", "% pupils FSM"))

# Plot the feature values
cols <- c(navy, coral)
names(cols) <- c("Synthetic MAT", id_group)

print(ggplot(data = comparison_raw, aes(x = Year, y = Value, group = Unit)) +
        geom_line(data = comparison_raw[comparison_raw$Unit == id_group, ], aes(col = paste(id_group))) +
        geom_point(data = comparison_raw[comparison_raw$Unit == id_group, ], aes(col = paste(id_group))) +
        geom_line(data = comparison_raw[comparison_raw$Unit == "Synthetic MAT", ], aes(col = "Synthetic MAT")) +
        geom_point(data = comparison_raw[comparison_raw$Unit == "Synthetic MAT", ], aes(col = "Synthetic MAT")) +
        facet_wrap(vars(Variable), ncol = 1, scales = "free_y") +
        labs(title = "Feature timeseries without covariate adjustment",
             x = "Academic year",
             y = "Reported value") +
        ambition_theme +
        theme(axis.text.x = element_text(angle = 45, hjust = 1),
              legend.title = element_blank(),
              strip.text = element_text(size = 10)) +
        scale_color_manual(
          breaks=c(id_group, "Synthetic MAT"),
          values=cols) +
        scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str)
)

if (!is.null(scest.out$data$C)) {
  
  # Access and examine the raw features for the control units (B) **and the covariates (C)**
  # Each row represents a different feature-year combination for the control units, and each column represents a different control unit.
  control_features <- cbind(scest.out$data$B, scdata.out$C)
  
  # Access and examine matrix *b*, containing the synthetic control weights (w) and values of the covariate adjustment (r)
  b <- scest.out$est.results$b # a matrix containing w (a matrix containing the estimated weights of the donors) and r (a matrix containing the values of the covariates used for adjustment)
  
  # Compute the synthetic control's pre-treatment feature values
  synthetic_features_adjusted <- control_features %*% b # this is how scest.out$est.results$A.hat is internally computed
  
  # Compare the treated and synthetic control feature values
  comparison_adjusted <- cbind(treated_features, synthetic_features_adjusted)
  colnames(comparison_adjusted) <- c(id_group, "Synthetic MAT")
  comparison_adjusted <- as.data.frame(comparison_adjusted)
  comparison_adjusted$Variable <- row.names(comparison_adjusted)
  comparison_adjusted$Year <- as.numeric(stringi::stri_extract_last_regex(comparison_adjusted$Variable, "\\d{4}"))
  comparison_adjusted$Variable <- gsub("[[:digit:]]+", "", comparison_adjusted$Variable)
  comparison_adjusted$Variable <- gsub(".", "", comparison_adjusted$Variable, fixed = T)
  
  # Make data long for plotting
  comparison_adjusted <- reshape2::melt(comparison_adjusted, id.var = c("Variable", "Year"), value.name = "Value", variable.name = "Unit")
  comparison_adjusted$Variable <- factor(comparison_adjusted$Variable,
                                         levels = c("pupil_to_qual_teacher_ratio", "fte_avg_age", "pnpupfsm_e"),
                                         labels = c("Outcome", "Teacher age", "% pupils FSM"))
  
  # Plot the feature values
  print(ggplot(data = comparison_adjusted, aes(x = Year, y = Value, group = Unit)) +
          geom_line(data = comparison_adjusted[comparison_adjusted$Unit == id_group, ], aes(col = paste(id_group))) +
          geom_point(data = comparison_adjusted[comparison_adjusted$Unit == id_group, ], aes(col = paste(id_group))) +
          geom_line(data = comparison_adjusted[comparison_adjusted$Unit == "Synthetic MAT", ], aes(col = "Synthetic MAT")) +
          geom_point(data = comparison_adjusted[comparison_adjusted$Unit == "Synthetic MAT", ], aes(col = "Synthetic MAT")) +
          facet_wrap(vars(Variable), ncol = 1, scales = "free_y") +
          labs(title = "Feature timeseries with covariate adjustment",
               x = "Academic year",
               y = "Reported value") +
          ambition_theme +
          theme(axis.text.x = element_text(angle = 45, hjust = 1),
                legend.title = element_blank(),
                strip.text = element_text(size = 10)) +
          scale_color_manual(
            breaks=c(id_group, "Synthetic MAT"),
            values=cols) +
          scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str)
  )
  
}
cat("\n\n")



```


```{r proc grid, eval = F, include=F}
# declare file name
file_name <- file.path(dir, "03_scm_mat", "interim", paste0("03_treated_mat_scpi_cv_", tolower(phase), "_results.csv"))

# read in results
results <- read.csv(file_name)

#### process data grid search ####

# copy data for editing
results_fit <- results

# --- create new vars for facets --- #

# timeseries processing options #
# min years per school
results_fit$min.years.obs <- paste0(results_fit$min.years.obs, "Y")
results_fit$min.years.obs <- factor(results_fit$min.years.obs)
# min schools per year
results_fit$min.schools.per.timeperiod <- paste0(results_fit$min.schools.per.timeperiod, "S/Y")
results_fit$min.schools.per.timeperiod <- factor(results_fit$min.schools.per.timeperiod)
# min schools per mat
results_fit$min.schools.per.mat <- paste0(results_fit$min.schools.per.mat, "S")
results_fit$min.schools.per.mat <- factor(results_fit$min.schools.per.mat)

# did we remove outliers
results_fit$excl.out <- ifelse(results_fit$excl.outlier, "excl. out", "incl. out")

# donor pool filtering options # 

# which region was used for filtering
results_fit$region <- ifelse(grepl("North West", results_fit$regions), "YS&H + NW", "YS&H")
results_fit$region <- factor(results_fit$region)
# were any MATs excluded?
if (phase == "mixed") {
  results_fit$phase <- ifelse(results_fit$exclude.single.phase, "excl. single phase", "incl. single phase")
  results_fit$phase <- factor(results_fit$phase)
} else {
  results_fit$phase <- "same phase"
  results_fit$phase <- factor(results_fit$phase)
}

# SCM setup options in scpi #

# is DV in features?
results_fit$feat_dv <- ifelse(grepl("ratio", results_fit$features), "incl. DV", "excl. DV")
results_fit$feat_dv <- factor(results_fit$feat_dv)

# covariate adjustment
results_fit$adj <- ifelse(is.na(results_fit$cov.adj), "none", results_fit$cov.adj)
results_fit$adj <- factor(results_fit$adj, levels = c("none", "constant", "trend", "constant, trend"),
                          labels = c("none", "Constant", "Trend", "C + T"))

# which years were used in training
results_fit$min_year <- sapply(results_fit$period.pre, function(x) extract_min_max_years(x)[1])
results_fit$max_year <- sapply(results_fit$period.pre, function(x) extract_min_max_years(x)[2])
results_fit$period.pre <- paste0(results_fit$min_year, ":", results_fit$max_year)
results_fit$period.pre <- factor(results_fit$period.pre)

# which constraints were applied to the weights
results_fit$method <- tstrsplit(results_fit$w.constr, "; ")[[1]]
results_fit$method <- gsub("name = ", "", results_fit$method)
results_fit$method <- factor(results_fit$method, levels = c("simplex", "L1-L2", "lasso", "user provided"))

# compute fit stats
results_fit <- results_fit %>%
  # create one col per rmspe
  mutate(
    sd_all = sd_treated[cross.val == F],
    rmspe_all = rmspe_pre[cross.val == F], 
    rmspe_T = rmspe_pre[cross.val == T], 
    rmspe_V = rmspe_post[cross.val == T],
    .by = it
  ) %>%
  # compute ratios #
  # if ratio is below 1: worse fit in training than in validation data
  # if ratio is above 1: worse fit in training than in validation data
  # if ratio is equal to 1: equal fit in training and validation data
  mutate(ratio = rmspe_V / rmspe_T) %>%
  # remove all CV runs
  filter(cross.val == F)

```


```{r sims, eval=FALSE, include=F}
# compute ratio of post-treatment RMSPE To pre-treatment RMSPE                                                  
rmspe <- function(x){sqrt(mean(x^2))}

# Calculate directional gaps: Use only negative post-treatment gaps
# negative because we would predict that the treatment LOWERS the DV pupil-to-teacher ratio
directional_postrmspe <- function(unit_id) {
  post_gaps <- storegaps[(length(period.pre)+1):nrow(storegaps), unit_id]
  negative_gaps <- post_gaps[post_gaps < 0]  # Focus on negative deviations
  if(length(negative_gaps) == 0) return(0)   # Handle no negative gaps
  sqrt(mean(negative_gaps^2))                # RMSPE of negative gaps
}

# process data from placebo runs #

# determine file pattern - CHANGE
pattern = paste0("07_treated_mat_scpi_perm_", tolower(phase), "_it_", sprintf("%03d", ii))

# list all files
files = sort(list.files(path = file.path(dir, "03_scm_mat", "interim"), pattern = pattern, full.names = T))
files <- files[grepl(sprintf("%.2f", decrease), files)] # focus on this decrease

if (length(files) > 0) {
  
  for (f in 1:length(files)) {
    
    file = files[f]
    
    # read in results
    storegaps <- read.csv(file)
    names(storegaps)[1] <- "time_period"
    names(storegaps) <- gsub("X", "", names(storegaps))
    
    # compute RMPSE for pre and post
    prermspe <- apply(storegaps[1:length(period.pre), -1], 2, rmspe)
    postrmspe <- apply(storegaps[(1+length(period.pre)):(length(period.pre)+length(period.post)), -1], 2, rmspe)
    # compute post to pre ratio
    ratio <- sort(postrmspe/prermspe)
    # determine ratio in treated unit
    observed_ratio <- ratio[names(ratio) == uid_treated]
    # permutation distribution of ratios
    permutation_ratios <- c(ratio)  # Includes treated unit's ratio
    
    # compute directional rmspe values for post
    # this only takes into consideration the any negative deviations in the gap when computing the RMSPE
    postrmspe_neg <- sapply(colnames(storegaps)[-1], directional_postrmspe)
    # compute post to pre ratio using directional rmspe post values
    ratio_negative <- postrmspe_neg / prermspe  # Directional RMSPE ratio
    # determine ratio in treated unit
    observed_ratio_neg <- ratio_negative[names(ratio_negative) == uid_treated]
    # permutation distribution of directional ratios
    permutation_ratios_neg <- ratio_negative  # Includes all units (treated + placebos)
    
    # compute treatment effect: mean post-treatment gap for treated unit
    postgap <- apply(storegaps[(1+length(period.pre)):(length(period.pre)+length(period.post)), -1], 2, mean)
    avg_gap_post <- postgap[names(postgap) == uid_treated]
    
    # effect in national SD
    eff_gap_pooled_sd <- avg_gap_post / pooled_sd

    # combine permutation data into df
    perm_results <- data.frame(group_uid = names(prermspe),
                               rmspe_pre = prermspe,
                               rmspe_post = postrmspe,
                               ratio = postrmspe / prermspe,
                               rmspe_post_neg = postrmspe_neg,
                               ratio_neg = postrmspe_neg / prermspe,
                               gap_post = postgap)
    
    # identify ill-fitting placebo runs
    fit_threshold <- perm_results$rmspe_pre[perm_results$group_uid == uid_treated] * 5
    perm_results$ill_fitted <- perm_results$rmspe_pre > fit_threshold
    n_ill <- sum(perm_results$ill_fitted == T)
    cutoff_value <- quantile(perm_results$ratio, 0.95, na.rm = T)
    cutoff_thresh5 <- quantile(perm_results$ratio[perm_results$ill_fitted == F], 0.95, na.rm = T)
    
    # compute two-sided p values
    prob_two_sided <- sum(perm_results$ratio >= observed_ratio) / length(perm_results$ratio)
    prob_two_sided_thresh5 <- sum(perm_results$ratio[perm_results$ill_fitted == F] >= observed_ratio) / sum(perm_results$ill_fitted == F)
    
    # determine if the p values are significant
    sig_two_sided <- prob_two_sided < .05
    sig_two_sided_thresh5 <- prob_two_sided_thresh5 < .05
    
    # compute one-sided p values
    prob_one_sided <- sum(perm_results$ratio_neg >= observed_ratio_neg) / length(perm_results$ratio_neg)
    prob_one_sided_thresh5 <- sum(perm_results$ratio_neg[perm_results$ill_fitted == F] >= observed_ratio_neg) / sum(perm_results$ill_fitted == F)
    
    # determine if the p values are significant
    sig_one_sided <- prob_one_sided < .05
    sig_one_sided_thresh5 <- prob_one_sided_thresh5 < .05
    
    # initialise df for results
    sim <- data.frame(
      group_uid = uid_treated,
      mat = id_group,
      n_donors = ncol(storegaps)-1,
      reduction = decrease,
      file = file,
      sim = f,
      eff_gap = avg_gap_post,
      eff_gap_pooled_sd = eff_gap_pooled_sd,
      export = paste(round(avg_gap_post, 2), "/", round(eff_gap_pooled_sd, 2)),
      rmspe_pre = perm_results$rmspe_pre[perm_results$group_uid == uid_treated],
      rmspe_post = perm_results$rmspe_post[perm_results$group_uid == uid_treated],
      rmspe_ratio = perm_results$ratio[perm_results$group_uid == uid_treated],
      rmspe_post_neg = perm_results$rmspe_post_neg[perm_results$group_uid == uid_treated],
      rmspe_ratio_neg = perm_results$ratio_neg[perm_results$group_uid == uid_treated],
      n_ill = n_ill,
      prob_two_sided = prob_two_sided,
      sig_two_sided = sig_two_sided,
      prob_two_sided_thresh5 = prob_two_sided_thresh5,
      sig_two_sided_thresh5 = sig_two_sided_thresh5,
      prob_one_sided = prob_one_sided,
      sig_one_sided = sig_one_sided,
      prob_one_sided_thresh5 = prob_one_sided_thresh5,
      sig_one_sided_thresh5 = sig_one_sided_thresh5
    )
    
    if (f == 1 & decrease == 0) {
      df_sim <- sim
    } else {
      df_sim <- rbind(df_sim, sim)
    }
    
  }
  
}

```

```{r power, eval=FALSE, include=F}
# add decrease in percent
df_sim$decrease = factor(paste0(df_sim$reduction * 100, "%"), levels = paste0(0:10, "%"))

# get counts and power obtained across all simulations for this setting #
power <- df_sim %>% 
  group_by(decrease) %>% 
  summarise(
    n_ill = mean(n_ill),
    n_sig_two_sided = sum(sig_two_sided_thresh5),
    power_two_sided_num = 100 * sum(sig_two_sided_thresh5)/n(),
    power_two_sided = paste0(power_two_sided_num, "%"),
    n_sig_one_sided = sum(sig_two_sided_thresh5),
    power_one_sided_num = 100 * sum(sig_one_sided_thresh5)/n(),
    power_one_sided = paste0(power_one_sided_num, "%")
  )

row_idx <- which(power$power_one_sided_num >= 80) 
  
# compute descriptive stats
vars_to_check <- c("eff_gap", "eff_gap_pooled_sd", "rmspe_pre", "rmspe_post", "rmspe_ratio", "rmspe_post_neg", "rmspe_ratio_neg")

out <- 
  # compute descriptive stats
  rbind(
    do.call("rbind", psych::describeBy(df_sim[, vars_to_check], group = df_sim[, "decrease"]))
  ) %>%
  # add decrease and vars from row.names, round values and ensure that they all have two digits
  mutate(
    decrease = sub("%.*", "%", row.names(.)),
    vars = sub(".*%.", "", row.names(.)),
    across(where(is.numeric), ~ round(.x, digits = 2)),
    across(where(is.numeric), ~ sprintf("%.2f", .x))
  ) %>%
  # make decrease factor and create summary string
    mutate(
    decrease = factor(decrease, levels = paste0(0:10, "%")),
    vars = factor(vars, levels = vars_to_check),
    summary = paste0(mean, " (", sd, ") ", "[", min, ";", max, "]")
  ) %>%
  # drop vars and arrange columns
  select(vars, decrease, summary) %>%
  relocate(vars, decrease) %>%
  arrange(vars, decrease) %>%
  tibble::remove_rownames(.) %>%
  # make data wide
  tidyr::pivot_wider(names_from = vars, values_from = summary) %>%
  # merge with counts and power obtained
  as.data.frame()

# print to markdown
full_join(power, out) %>%
  select(-c(power_two_sided_num, power_one_sided_num)) %>%
  kbl(row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>%
  row_spec(row_idx, bold = T) %>%
  print()
  

# plot results of all simulations #

# faceted histogram - two sided test
plt <- ggplot(data = df_sim) +
  geom_histogram(aes(x = prob_two_sided_thresh5, fill = sig_two_sided_thresh5), binwidth = 0.01, boundary = 0, colour = "black", position = "identity") +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(axis.title.y = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_fill_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  xlab("p value (two-sided)") +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")
# faceted histogram - one sided test
plt <- ggplot(data = df_sim) +
  geom_histogram(aes(x = prob_one_sided_thresh5, fill = sig_one_sided_thresh5), binwidth = 0.01, boundary = 0, colour = "black", position = "identity") +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(axis.title.y = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_fill_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  xlab("p value (one-sided)") +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")

# scatter plot of probability and effect size - two sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_two_sided_thresh5, y = eff_gap, col = sig_two_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  ylab("Average treatment effect (treated - synth)") +
  xlab("p value (two-sided)") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")
# scatter plot of probability and effect size - one sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_one_sided_thresh5, y = eff_gap, col = sig_one_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  ylab("Average treatment effect (treated - synth)") +
  xlab("p value (one-sided)") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")

# scatter plot of probability and effect size - two sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_two_sided_thresh5, y = eff_gap/pooled_sd, col = sig_two_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "left") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral) + 
  xlab("p value (two-sided)") +
  scale_y_continuous(
    "Eff (abs) = mean(treated – synth)", 
    sec.axis = sec_axis(~ . / pooled_sd, name = "Eff (pooled SD) = Eff (abs) / pooled national SD ")
  )
print(plt)
cat("\n\n")
# scatter plot of probability and effect size - one sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_one_sided_thresh5, y = eff_gap/pooled_sd, col = sig_one_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "left") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral) + 
  xlab("p value (one-sided)") +
  scale_y_continuous(
    "Eff (abs) = mean(treated – synth)", 
    sec.axis = sec_axis(~ . / pooled_sd, name = "Eff (pooled SD) = Eff (abs) / pooled national SD ")
  )
print(plt)
cat("\n\n")

# scatter plot of probability and effect size - two sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_two_sided_thresh5, y = eff_gap/pooled_sd, col = sig_two_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "left") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral) + 
  xlab("p value (two-sided)") +
  scale_y_continuous(
    paste0("Change in ratio where 0 equals ", round(starting_ratio, 2)), 
    sec.axis = sec_axis(~ calculate_change_in_teachers(starting_ratio, ., num_pupils), name = paste0("Change in teacher FTE where 0 equals ", round(num_teach, 2)))
  )
print(plt)
cat("\n\n")
# scatter plot of probability and effect size - one sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_one_sided_thresh5, y = eff_gap/pooled_sd, col = sig_one_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "left") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral) + 
  xlab("p value (one-sided)") +
  scale_y_continuous(
    paste0("Change in ratio where 0 equals ", round(starting_ratio, 2)), 
    sec.axis = sec_axis(~ calculate_change_in_teachers(starting_ratio, ., num_pupils), name = paste0("Change in teacher FTE where 0 equals ", round(num_teach, 2)))
  )
print(plt)
cat("\n\n")

# scatter plot of probability and ratio - two sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_two_sided_thresh5, y = rmspe_ratio, col = sig_two_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  ylab("Ratio of RMSPE (post) to RMSPE (pre)") +
  xlab("p value (two-sided)") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_two_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")
# scatter plot of probability and ratio - one sided
plt <- ggplot(data = df_sim) +
  geom_vline(xintercept = 0.05, linetype = "dashed") +
  geom_point(aes(x = prob_one_sided_thresh5, y = rmspe_ratio_neg, col = sig_one_sided_thresh5)) +
  facet_wrap(vars(decrease), ncol = 2, strip.position = "right") +
  ambition_theme +
  theme(#axis.title.x = element_blank(), 
        strip.text = element_text(size = 10, face = "bold"),
        axis.text = element_text(size = 10), 
        legend.position = "none") +
  xlab("p value (one-sided)") +
  ylab("Ratio of RMSPE (post negative) to RMSPE (pre)") +
  scale_colour_manual(values = c("TRUE" = coral, "FALSE" = navy40)) +
  geom_text(data = df_sim %>% filter(sig_one_sided_thresh5 == TRUE) %>% group_by(decrease) %>% summarise(count = n()), 
            aes(x = Inf, y = Inf, label = paste(count, "out of", length(files), "simulations below 0.05")),
            hjust = 1.1, vjust = 1.1, size = 4, colour = coral)
print(plt)
cat("\n\n")


# determine output filename
file_name <- file.path(dir, "03_scm_mat", "interim", paste0(file_stem, "_" , tolower(phase), "_it_", sprintf("%03d", ii), ".csv"))
# df_sim <- read.csv(file_name)
# save output
write.csv(df_sim, file = file_name, row.names = FALSE)

```

```{r run_code, echo=F, message=FALSE, results='asis', fig.align='center', fig.height=6, fig.width=8, out.width='100%', out.height='100%'}

### Process data ###

# Set options for data preparation
id.var <- "group_uid" # ID variable
time.var <- "time_period" # Time variable
outcome.var <- "pupil_to_qual_teacher_ratio" # Dependent variable

w.constr <- list(name = "simplex") # use canonical SC

# default options
target_regions <- c("Yorkshire and the Humber", "North West")
min.years.obs <- 8

#### RUN PERMUTATION IN LOOP ####

# specify increments for decrease
increments <- seq(0, .1, 0.01)


#### SIMULATE DATA IN LOOP ####
# define phases to loop through
phases <- c("mixed", "Secondary", "Primary")
phases <- c("mixed")

headings <- c("Whole MAT", "Secondary schools only", "Primary schools only")
p = 1 # debug
s = 1
k = 5

period.pre <- 2010:2023
period.post <- 2024:2026

for (p in 1:length(phases)) {
  
  cat("# ", headings[p], "\n\n")
  
  phase = phases[p]
  
# get grid search results
<<proc grid>>
  
  # define different filter option for each phase #
  
  if (phase == "mixed") {
    filter_phase = c("Not applicable", "16 plus")
    it <- c(197, 217, 277, 237, 297)
  } else if (phase == "Secondary") {
    filter_phase = unique(groups$phaseofeducation_name)[!grepl("econdary", unique(groups$phaseofeducation_name))]
  } else if (phase == "Primary") {
    filter_phase = unique(groups$phaseofeducation_name)[!grepl("imary", unique(groups$phaseofeducation_name))]
  }
  
  ii = it[1] # debug
  
  # loop through years available
  for (y in 1:length(unique(results_fit$period.pre))) {
    
    years <- unique(as.character(results_fit$period.pre))[y]
    
    
    if (nrow(results_fit[results_fit$period.pre == years & results_fit$it %in% it, ]) > 0) {
      
      cat("## Pre-treatment timeseries", years, "\n\n")
      
      # identify the iterations for this TS
      it_tmp <- results_fit$it[results_fit$period.pre == years & results_fit$it %in% it]

      # loop through the iterations in this TS
      for (ii in it_tmp) {
    
        cat("### Settings", ii, "\n\n")
        
        # select params
        params_out <- results_fit[results_fit$it == ii & !results_fit$cross.val, ]
        
        # show params in markdown
        out_params <- params_out %>%
          mutate(
            pretreat = paste0(min_year, ":", max_year)
          ) %>%
          select(it, pretreat, feat_dv, adj, phase, min.schools.per.timeperiod, min.schools.per.mat, 
                 n_pool, n_active,
                 sd_all, rmspe_all, rmspe_T, rmspe_V, ratio#, m_gap, sd_gap, min_gap, max_gap
          ) %>%
          rename("S/Y" = min.schools.per.timeperiod, "S/M" = min.schools.per.mat)
        
        # print #
        kbl(out_params, row.names = F, digits = 3) %>%
          kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>% 
          print()
        cat("\n\n")
        
        
        
        # process data at MAT level
        
        # select params
        params <- results[results$it == ii & !results$cross.val, ]
        
        process_data_scm_mat(uid_treated = uid_treated, target_regions = target_regions, filter_phase = filter_phase,
                             swf_filter = params$swf.filter, 
                             min_years_obs = min.years.obs, 
                             min_schools_per_timeperiod = params$min.schools.per.timeperiod, min_schools_per_mat = params$min.schools.per.mat)
        
        # Apply more filtering
        if (params$exclude.single.phase) {
          # remove MATs from MATs
          MATs$multiple_phases <- grepl(" | ", MATs$phase, fixed = T)
          MATs <- MATs[MATs$multiple_phases, ]
          # remove average MAT ts
          df_avg <- df_avg[df_avg$group_uid %in% MATs$group_uid, ]
          # remove school TS
          df <- df[df$group_uid %in% MATs$group_uid, ]
        }
        
        # show MAT level Y-o-Y changes in outcome
        swf %>% filter(laestab %in% df$laestab[df$group_uid == uid_treated]) %>%
          select(laestab, time_period, pupils_fte, qualified_teachers_fte, pupil_to_qual_teacher_ratio) %>%
          group_by(laestab, time_period) %>%
          group_by(time_period) %>%
          summarise(
            schools = sum(!is.na(pupil_to_qual_teacher_ratio)),
            pupils_fte = mean(pupils_fte, na.rm = T),
            qualified_teachers_fte = mean(qualified_teachers_fte, na.rm = T),
            pupil_to_qual_teacher_ratio = mean(pupil_to_qual_teacher_ratio, na.rm = T)
          ) %>%
          mutate(
            ratio_change = pupil_to_qual_teacher_ratio - lag(pupil_to_qual_teacher_ratio, default = pupil_to_qual_teacher_ratio[1]),
            teacher_fte_change = qualified_teachers_fte - lag(qualified_teachers_fte, default = qualified_teachers_fte[1]),
            pupils_fte_change = pupils_fte - lag(pupils_fte, default = pupils_fte[1])
          ) %>%
          kbl(row.names = F, digits = 2) %>%
          kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>%
          print()
        
        # prepare data and estimate scm
        cat("#### SCM for pre-treatment data \n\n")
        apply_effects <- FALSE
        <<est>>
          # inspect results
          <<res>>
          
          
          for (k in 1:length(increments)) {
            
            decrease = increments[k]
            
            # run grid search
            cat("##### ", decrease * 100, "% decrease in ratio \n\n")
            # prepare data and estimate scm
            apply_effects <- TRUE
            <<est>>

            # process all simulations
            <<sims>>
          }
        
        # determine output filename
        file_name <- file.path(dir, "03_scm_mat", "interim", paste0(file_stem, "_" , tolower(phase), "_it_", sprintf("%03d", ii), ".csv"))
        # df_sim <- read.csv(file_name)
        # save output
        write.csv(df_sim, file = file_name, row.names = FALSE)
        
        
        # show outputc
        cat("#### Power simulations \n\n")
        # result of power simulations
        <<power>>
          
  }
      
    }

  }

  
  
}
```
