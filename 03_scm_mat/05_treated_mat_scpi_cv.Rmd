---
title: "Results of cross-validated gridsearch with *scpi* package"
author: "Stefanie Meliss"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    self_contained: true
---
This markdown summarises the results of the grid search.  

The grid search iterated through the following parameters:  

- Was the outcome included as feature? (excl. DV vs. incl. DV)  
- Was any covariates adjusted for each feature? (none vs. Constant vs. Trend vs. Constant + Trend)  
- How many years of observations did each school need to have to be included at MT level? (4 vs. 6 vs. 8) **based on previous data exploration steps, we're focusing on schools with at least 8 years of observations**    
- How many schools needed to have an observation for a specific year for the year to be included? (2 vs. 3 vs. 4)  
- How many complete school timeseries needed to be available at MAT level? (2 vs. 3 vs. 4)  
- Which years were included in the training data? (all years between 2010/11 and 2021/22 vs. excl. 2010/11 - 2011/12 vs.  excl. 2010/11 - 2013/14)  
- Which schools were included in the donor pool? (Schools in the same region vs. schools in same and neighbouring region) **based on previous data exploration steps, we're focusing on schools in same and neighbouring region**    
- Where trusts excluded if all their schools were located in the neighbouring region only? (yes vs. no)  **based on previous data exploration steps, we've excluded this step**    
- At whole trust level, Where trusts excluded if their timeseries was based on one phase only? (yes vs. no)  
- Which weight constraints were defined during the estimation? (Simplex vs. L1-l2)  
- Was data from outlying schools excluded for Dixon? **based on previous data exploration steps, we've excluded outlying schools**


Data up to 2021/22 was used to estimate the weights under various settings. The weights were validated using data from 2022/23 and 2023/24. We also applied the settings to the whole timeseries.    

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen = 999)
# empty work space
rm(list = ls())
gc()

# load libraries
library(kableExtra)
library(dplyr)
library(data.table)
library(ggplot2)

# create function to source code
source_code <- function(root_dir_name = "code", target_repo = "helper_functions", branch = "main", file_name = "file.R") {
  
  # construct URL
  git_url <- paste0("https://raw.githubusercontent.com/stefaniemeliss/", target_repo, "/", branch, "/", file_name)
  
  # attempt to download from github
  tempp_file <- tempfile(fileext = ".R")
  message <- curl::curl_download(git_url, tempp_file, quiet = F)
  
  if(!grepl("Error", message)) {
    
    # if successful, source file
    source(tempp_file)
    remove(tempp_file)
    
  } else { # load local copy of file
    
    # Get the current working directory
    current_dir <- getwd()
    
    # Split the current directory into its components
    dir_components <- strsplit(current_dir, "/")[[1]]
    
    # Identify the root directory dynamically based on the provided root directory name
    root_index <- which(dir_components == root_dir_name)
    if (length(root_index) == 0) {
      stop(paste("Root directory", root_dir_name, "not found in the current path"))
    }
    root_dir <- do.call(file.path, as.list(dir_components[1:root_index]))
    
    # Identify the subdirectory one level below the root and construct its absolute path
    project_repo <- dir_components[root_index + 1]
    dir <- file.path(root_dir, project_repo)
    
    if (target_repo != project_repo) {
      dir <- gsub(project_repo, target_repo, dir) 
    }
    
    # Construct the full file path
    file_path <- file.path(dir, file_name)
    
    # Print the directory and file path for debugging
    print(paste("Directory:", dir))
    print(paste("File path:", file_path))
    
    # Source the file into the parent frame
    source(file_path, local = parent.frame())
  }
}

# source functions
source_code(target_repo = "scm_feasibility", file_name = "functions.R")

# Define the base directory
dir <- get_directory()
dir_data <- file.path(dir, "data")
dir_misc <- file.path(dir, "misc")

# get file stem name
file_stem <- get_file_stem()

# copy data #
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_swf.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_pupils.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_search.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_groups.csv"), dir_data, overwrite = T)

# load data #

swf <- fread(file.path(dir_data, "data_swf.csv"))
pup <- fread(file.path(dir_data, "data_pupils.csv"))
est <- fread(file.path(dir_data, "data_establishments_search.csv"), na.strings = "")
groups <- fread(file.path(dir_data, "data_establishments_groups.csv"), na.strings = "")

uid_treated <- 2939

# Dixon schools
dix <- groups %>% filter(group_uid == uid_treated)

# get establishment data from treated schools
list_laestab <- c(dix$laestab)

# create lookup 
lookup <- data.frame(time_period = sort(unique(swf$time_period)))
lookup$time_period_str <- insert_slash(lookup$time_period)
lookup$time_period <- as.numeric(substr(lookup$time_period, 0, 4))

```



```{r plot_ts, echo=FALSE, eval=F}
# compute timeseries descriptives
ts_desc <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){psych::describe(x, IQR = T, trim = 1/nrow(df_treat))})

# combine to df
ts_desc <- do.call("rbind",ts_desc)
ts_desc$vars <- NULL

ts_desc$out_sd <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){sum(is_outlier_3sd(x))})
ts_desc$out_iqr <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){sum(is_outlier_iqr(x))})

# compute snr
ts_desc$snr <- apply(df[, grepl("pup|fte", names(df))], MARGIN = 2, FUN = function(x){calculate_snr(x, window_size = 3)})

# compute relative standard deviation
ts_desc$rsd <- ts_desc$sd / ts_desc$mean

# compute timeseries auto correlation
max_lag = ceiling(.25 * nrow(df_treat)) # use lags up to about one-quarter of the total number of observations.
ts_ac <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){
  df_treat <- acf(ts(x), lag.max = max_lag, plot = F)
  return(df_treat$acf)
})

# transpose output
ts_ac <- as.data.frame(t(ts_ac))
names(ts_ac) <- paste0("ac_l", 0:(ncol(ts_ac)-1))
ts_ac$ac_l0 <- NULL

# combine all measures
out <- merge(ts_desc, ts_ac, by = 0)
names(out)[1] <- "Variable"

# assign new variable names
out$Variable <- factor(out$Variable, 
                       levels = c("pupil_to_qual_teacher_ratio",  
                                  "fte_avg_age",
                                  "pnpupfsm_e"
                                  ),
                       labels = c("Outcome",
                                  "Age",
                                  "FSM")
                       
)
# sort 
out <- out[order(out$Variable), ]

# print to markdown
out %>% 
  arrange(Variable) %>%
  kbl(caption = paste0("Descriptives of MAT timeseries data"), row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>% 
  column_spec(c(2, 18), border_right = T) %>%
  column_spec(c(1, 4, 17), bold = T) %>%
  print()
cat("\n")



# get school-level data of treated MAT
df_s <- df %>% filter(laestab %in% list_laestab)

# create data in long format - school level
df_s <- df_s %>%
  tidyr::pivot_longer(
    cols = c(pupil_to_qual_teacher_ratio, fte_avg_age, pnpupfsm_e),
    names_to = "variable") %>%
  mutate(category = case_match(variable, 
                               "pupil_to_qual_teacher_ratio" ~ "Outcome",
                               "fte_avg_age" ~ "Teacher age",
                               "pnpupfsm_e" ~ "% pupils FSM")) %>%
  as.data.frame()

df_s$category <- factor(df_s$category, levels = c("Outcome", "Teacher age", "% pupils FSM"))

# create data in long format - MAT
df_long <- df_treat %>%
  tidyr::pivot_longer(
    cols = c(pupil_to_qual_teacher_ratio, fte_avg_age, pnpupfsm_e),
    names_to = "variable") %>%
  mutate(category = case_match(variable, 
                               "pupil_to_qual_teacher_ratio" ~ "Outcome",
                               "fte_avg_age" ~ "Teacher age",
                               "pnpupfsm_e" ~ "% pupils FSM")) %>%
  as.data.frame()

df_long$category <- factor(df_long$category, levels = c("Outcome", "Teacher age", "% pupils FSM"))

# determine time period
period.avail <- sort(unique(df_long$time_period))
period.pre <- setdiff(period.avail, c(2022:2023)) # Pre-treatment period


##### CREATE SPAGHETTI PLOT ####

# plot MAT AVERAGE timeseries for each variable
# note: school-level data is added to the plot but in transparent (col = NA)
# this keeps the scales constant
plt <- ggplot(data = df_long, aes(x = time_period, y = value, group = group_uid)) +
  geom_point(data = df_s, aes(x = time_period, y = value), col = NA) + 
  geom_vline(xintercept = period.pre[length(period.pre)]+0.5, linetype = "dotted") +
  geom_line(col = black, linewidth = .8) + 
  geom_point(aes(colour = factor(n)), size = 3) +
  facet_wrap(~ category, ncol = 1, strip.position = "top", scales = "free_y") +
  ambition_theme +
  ylab("Reported value") + xlab("Academic year") + labs(col = "Number of schools averaged") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.title = element_blank(),
        legend.position = "bottom") +
  scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str) +
  scale_color_manual(values = ambition_palette_bright)

suppressWarnings(print(plt))
cat("\n\n")  # Add some space between plots


# plot MAT AVERAGE timeseries for each variable
# add school-level data visibly as LINES
plt <- ggplot() + 
  geom_vline(xintercept = period.pre[length(period.pre)]+0.5, linetype = "dotted") +
  geom_line(data = df_s, aes(x = time_period, y = value, colour = establishmentname, group = establishmentname), linewidth = .5) + 
  geom_line(data = df_long, aes(x = time_period, y = value, group = group_uid), linewidth = 1) + 
  facet_wrap(~ category, ncol = 1, strip.position = "top", scales = "free_y") + 
  ambition_theme + 
  ylab("Reported value") + 
  xlab("Academic year") + 
  scale_x_continuous(breaks = lookup$time_period, labels = lookup$time_period_str) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.title = element_blank(), 
        legend.text = element_text(size = 8), 
        legend.position = "bottom", legend.box="vertical",
        legend.spacing = unit(0.2, "cm"), 
        legend.margin = margin(t = 0.1, r = 0.1, b = 0.1, l = 0.1, unit = "cm")) + 
  scale_fill_manual(values = as.vector(pals::glasbey(length(list_laestab)))) + 
  scale_shape_manual(values = c(21:24)) + 
  scale_colour_manual(values = as.vector(pals::glasbey(length(list_laestab)))) +
  guides(col = guide_legend(nrow = nrow_legend, byrow = T))

print(plt)
cat("\n\n")  # Add some space between plots

```



```{r proc grid ts, eval=FALSE, echo=F}
#### check timeseries effects ####

# declare file name
file_name <- file.path(getwd(), "interim", paste0("01_treated_mat_examine_dv_preds_", tolower(phase), ".csv"))

# read in results
results <- read.csv(file_name)

# copy data for editing
results_ts <- results

# copy data for editing and subset results
results_ts <- results %>%
  filter(min.years.obs == 8) %>%
  as.data.frame()

if (phase %in% c("mixed", "Primary")) {
  results_ts <- results_ts %>%
    filter(excl.outlier == T) %>%
    as.data.frame()
}

# create new vars for facets #
# How was the average timeseries obtained?
results_ts$min.years.obs <- paste0(results_ts$min.years.obs, "Y")
results_ts$min.years.obs <- factor(results_ts$min.years.obs)
results_ts$min.schools.per.timeperiod <- paste0(results_ts$min.schools.per.timeperiod, "S/Y")
results_ts$min.schools.per.timeperiod <- factor(results_ts$min.schools.per.timeperiod)
results_ts$min.schools.per.mat <- paste0(results_ts$min.schools.per.mat, "S")
results_ts$min.schools.per.mat <- factor(results_ts$min.schools.per.mat)

# which years were used in training
results_ts$period.pre <- factor(results_ts$period.pre)

# only use params that resulted in data
results_ts$error <- results_ts$pupil_to_qual_teacher_ratio == 0
results_ts <- results_ts[!results_ts$error, ]

# extract all possible combinations
grid_ts <- results_ts %>%
  select(c(min.years.obs, min.schools.per.mat, min.schools.per.timeperiod, 
           swf.filter, excl.outlier, period.pre)) %>%
  filter(!duplicated(.))

```

```{r plot grid ts, eval=FALSE, echo=F}
#### plot timeseries ####

xintercept = eval(parse(text = years))[length(eval(parse(text = years)))-2]+0.5

plt <- ggplot(data = df_plot[df_plot$level == "MAT", ], aes(x = time_period, y = pupil_to_qual_teacher_ratio, group = id)) + 
  geom_vline(xintercept = xintercept, linetype = "dotted") +
  geom_point(data = df_plot[df_plot$level == "School", ], aes(x = time_period, y = pupil_to_qual_teacher_ratio, col = name), size = 1) + 
  geom_line(linewidth = .8) +
  geom_point() +
  ggh4x::facet_grid2(cols = vars(min.years.obs, min.schools.per.timeperiod), rows = vars(period.pre, min.schools.per.mat), strip = ggh4x::strip_nested()) +
  ambition_theme +
  theme(strip.text = element_text(size = 10),
        legend.title = element_blank(),
        legend.text = element_text(size = 8),
        legend.position = "bottom", legend.box="vertical",
        legend.spacing = unit(0.2, "cm"), 
        legend.margin = margin(t = 0.1, r = 0.1, b = 0.1, l = 0.1, unit = "cm"),
        axis.title = element_text(size = 10),
        axis.text = element_text(size = 10),
        # axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1)
        #axis.text.x = element_blank()
        ) +
  scale_x_continuous(breaks = df_plot$time_period, labels = df_plot$time_period_str) +
  ylab("Reported value") + xlab("Academic year") +
  scale_colour_manual(values = as.vector(pals::glasbey(length(unique(df_plot$id[df_plot$level == "School"]))))) +
  scale_shape_manual(values = c(15:25)) +
  guides(col = guide_legend(nrow = nrow_legend, byrow = T))

print(plt)
cat("\n\n")
```


```{r proc grid param, eval=FALSE, echo=F}

#### process data grid search ####

# declare file name
file_name <- file.path(getwd(), "interim", paste0("03_treated_mat_scpi_cv_", tolower(phase), ".csv"))

# read in results
results <- read.csv(file_name)

# copy data for editing
results_fit <- results

# --- create new vars for facets --- #

# timeseries processing options #

# min years per school
results_fit$min.years.obs <- paste0(results_fit$min.years.obs, "Y")
results_fit$min.years.obs <- factor(results_fit$min.years.obs)
# min schools per year
results_fit$min.schools.per.timeperiod <- paste0(results_fit$min.schools.per.timeperiod, "S/Y")
results_fit$min.schools.per.timeperiod <- factor(results_fit$min.schools.per.timeperiod)
# min schools per mat
results_fit$min.schools.per.mat <- paste0(results_fit$min.schools.per.mat, "S")
results_fit$min.schools.per.mat <- factor(results_fit$min.schools.per.mat)

# did we remove outliers
results_fit$excl.out <- ifelse(results_fit$excl.outlier, "excl. out", "incl. out")

# donor pool filtering options # 

# which region was used for filtering
results_fit$region <- ifelse(grepl("North West", results_fit$regions), "YS&H + NW", "YS&H")
results_fit$region <- factor(results_fit$region)
# were any MATs excluded?
if (phase == "mixed") {
  results_fit$phase <- ifelse(results_fit$exclude.single.phase, "excl. single phase", "incl. single phase")
  results_fit$phase <- factor(results_fit$phase)
} else {
  results_fit$phase <- "same phase"
  results_fit$phase <- factor(results_fit$phase)
}

# SCM setup options in scpi #

# is DV in features?
results_fit$feat_dv <- ifelse(grepl("ratio", results_fit$features), "incl. DV", "excl. DV")
results_fit$feat_dv <- factor(results_fit$feat_dv)

# covariate adjustment
results_fit$adj <- ifelse(is.na(results_fit$cov.adj), "none", results_fit$cov.adj)
results_fit$adj <- factor(results_fit$adj, levels = c("none", "constant", "trend", "constant, trend"),
                          labels = c("none", "Constant", "Trend", "C + T"))

# which years were used in training
results_fit$min_year <- sapply(results_fit$period.pre, function(x) extract_min_max_years(x)[1])
results_fit$max_year <- sapply(results_fit$period.pre, function(x) extract_min_max_years(x)[2])
results_fit$period.pre <- paste0(results_fit$min_year, ":", results_fit$max_year)
results_fit$period.pre <- factor(results_fit$period.pre)

# which constraints were applied to the weights
results_fit$method <- tstrsplit(results_fit$w.constr, "; ")[[1]]
results_fit$method <- gsub("name = ", "", results_fit$method)
results_fit$method <- factor(results_fit$method, levels = c("simplex", "L1-L2", "lasso", "user provided"))

# create a bool capturing if there was an error
results_fit$error <- grepl("Error", results_fit$status)

# --- process data for plotting --- #

# create a grid with all combinations of variables evaluated
comb <- results_fit %>%
  # select parameter settings
  # only those not impacted by CV (hence not using period.pre)
  group_by(feat_dv, adj, region, phase, min_year, method, min.schools.per.timeperiod, min.schools.per.mat, min.years.obs) %>%
  # check that there are two each (CV == T and CV == F)
  summarise(n = n()) %>%
  ungroup() %>%
  # create column indexing the iteration
  mutate(it = as.character(1:nrow(.)))

# finalise dataset
results_fit <- results_fit %>%
  full_join(comb, .) %>%
  # select columns
  select(c(it, cross.val, 
           min.schools.per.timeperiod, min.schools.per.mat, min.years.obs, 
           region, phase, excl.out, 
           swf.filter, period.pre, period.post, min_year, max_year, 
           feat_dv, adj, method, 
           n_pool, sd_treated, rmspe_pre, rmspe_post, status, error))

# convert to long format
tmp_long <- results_fit %>%
  # from wide to long
  tidyr::pivot_longer(
    cols = c(rmspe_pre, rmspe_post),
    names_to = "data",
    values_to = "rmspe") %>%
  # remove all rows for rmspe in CV runs
  filter(!(cross.val == F & data == "rmspe_post")) %>%
  # rename
  mutate(data = case_match(data, 
                           "rmspe_pre" ~ "T",
                           "rmspe_post" ~ "V"  )) %>%
  mutate(data = ifelse(cross.val == F, "all", data)) %>%
  mutate(data = factor(data, levels = c("T", "V", "all"))) %>%
  # Explicitly arrange dataset by all relevant variables
  arrange(it, feat_dv, adj, region, phase, min.years.obs, min.schools.per.timeperiod, min.schools.per.mat, period.pre, method, data)


test <- tmp_long %>%
  mutate(sd_pre = sd_treated[data %in% "all"], .by = it) %>%
  mutate(check = rmspe < sd_treated[data %in% "all"], .by = it) %>%
  mutate(count = sum(check), .by = it) %>%
  mutate(rmspe_pre = rmspe[data %in% "T"], .by = it) %>%
  mutate(rmspe_post = rmspe[data %in% "V"], .by = it) %>%
  mutate(rmspe_all = rmspe[data %in% "all"], .by = it) %>%
  mutate(ratio_postpre = rmspe[data %in% "V"] / rmspe[data %in% "T"], .by = it) %>%
  mutate(ratio_allpre = rmspe[data %in% "all"] / rmspe[data %in% "T"], .by = it) %>%
  filter(count == 3) %>%
  select(-c(data, rmspe, check, count)) %>%
    filter(method == "simplex" & cross.val == F) %>%

  filter(!duplicated(.)) %>%
  #filter(ratio_postpre < 1.1 & ratio_postpre > .90)
  filter(min_year == 2014 & ratio_postpre < 2)


# Define explicit numeric dodge positions
method_levels <- unique(results_fit$method)
dodge_width <- 0.6
n_methods <- length(method_levels)
# Create evenly spaced numeric offsets around 0
method_positions <- seq(-dodge_width/2, dodge_width/2, length.out = n_methods)

# Create a lookup table
position_lookup <- tibble(
  method = method_levels,
  method_position = method_positions
) %>%
  mutate(method = factor(method, levels = c("simplex", "L1-L2", "lasso", "user provided"))
  )

# Merge these positions into your data
tmp_long <- tmp_long %>%
  left_join(position_lookup, by = "method") %>%
  mutate(
    data_numeric = as.numeric(factor(data)), # numeric x-axis position per 'data'
    x_position = data_numeric + method_position # final numeric position for plotting
  )



```

```{r plot grid param, eval=FALSE, echo=F}

#### plot data grid search ####

cat("### Effects on the model fit\n\n")

plt <- ggplot(data = df_plot, 
              aes(x = x_position, y = rmspe, group = it)) +
  geom_hline(data = function(y) y %>% filter(data == "all") %>% group_by(feat_dv, adj, min.schools.per.timeperiod, min.schools.per.mat, min_year, region, phase) %>% summarise(sd_treated = unique(sd_treated), .groups = 'drop'),
             aes(yintercept = sd_treated),color = black40, linetype = "dashed") +
  
  geom_point(aes(colour = method), size = 1) +
  geom_line(aes(colour = method)) +
  geom_label(data = df_plot[df_plot$data == "all", ], 
             aes(x = 2, y = 5.5, label = as.character(n_pool)), hjust = 0.5, vjust = 0.5) +
  scale_x_continuous(
    breaks = unique(df_plot$data_numeric),
    labels = unique(df_plot$data)
  ) +
  ggh4x::facet_grid2(cols = vars(phase, min.schools.per.timeperiod, min.schools.per.mat), rows = vars(feat_dv, adj), strip = ggh4x::strip_nested()) +
  ambition_theme +
  coord_cartesian(ylim = c(0, 6)) +
  theme(strip.text = element_text(size = 10),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        axis.title = element_text(size = 10),
        axis.text = element_text(size = 10),
        #axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        plot.caption = element_text(size = 10),
        legend.margin=margin(t = -8)) +
  ylab("Root Mean Squared Prediction Error (RMSPE)") +
  xlab("Cross-validation fold") +
  guides(colour = guide_legend(title = "Weight constraint")) +
  scale_colour_manual(values = ambition_palette_bright)
suppressWarnings(print(plt))
cat("\n\n")



```


```{r, echo=F, message=FALSE, results='asis', fig.align='center', fig.height=10, fig.width=13, out.width='100%', out.height='100%'}
# define phases to loop through
phases <- c("mixed", "Secondary", "Primary")

headings <- c("Whole MAT", "Secondary schools only", "Primary schools only")
p = 1 # debug
for (p in 1:length(phases)) {
  
  phase = phases[p]
  
  # define different filter option for each phase #
  
  if (phase == "mixed") {
    swf_filter = "! laestab %in% c(3802008) & ! time_period %in% c(201011, 201112)"
    filter_phase = c("Not applicable", "16 plus")
    nrow_legend = 2
  } else if (phase == "Secondary") {
    swf_filter = "! time_period %in% c(201011, 201112, 201213, 201314)"
    filter_phase = unique(groups$phaseofeducation_name)[!grepl("econdary", unique(groups$phaseofeducation_name))]
    nrow_legend = 2
  } else if (phase == "Primary") {
    swf_filter = "! laestab %in% c(3802008) & ! time_period %in% c(201011, 201112, 201213, 201314, 201415)"
    filter_phase = unique(groups$phaseofeducation_name)[!grepl("imary", unique(groups$phaseofeducation_name))]
    nrow_legend = 1
  }
  
  # Define target regions for filtering the donor pool
  regions <- c("Yorkshire and the Humber", "North West")
  
  
  cat("# ", headings[p], "\n\n")
  
  # process timeseries grid data
  <<proc grid ts>>
    
  # process fit grid data
  <<proc grid param>>
    
    # loop through years available
    for (y in 1:length(unique(results_ts$period.pre))) {
      
      years <- unique(as.character(results_ts$period.pre))[y]
      
      cat("## Pre-treatment timeseries", years, "\n\n")
      
      # subset ts data for plotting
      df_plot <- results_ts %>%
        filter(period.pre == years)
      
      # plot ts grid
      if (nrow(df_plot) > 0) {
        <<plot grid ts>>
          
          # process data at MAT level
          process_data_scm_mat(uid_treated = uid_treated, target_regions = regions, filter_phase = filter_phase,
                       swf_filter = unique(df_plot$swf.filter), min_years_obs = 8)
        
          # Plot timeseries
          <<plot_ts>>

      }

      # subset fit data for plotting
      year <- unlist(strsplit(years, ":"))[1]
      df_plot <- tmp_long %>%
        filter(min_year == as.numeric(year) & !error)
      
      # plot ts grid
      if (nrow(df_plot) > 0) {
        <<plot grid param>>
      }
      
      test <- tmp_long %>%
        mutate(sd_pre = sd_treated[data %in% "all"], .by = it) %>%
        mutate(check = rmspe < sd_treated[data %in% "all"], .by = it) %>%
        mutate(count = sum(check), .by = it) %>%
        mutate(rmspe_pre = rmspe[data %in% "T"], .by = it) %>%
        mutate(rmspe_post = rmspe[data %in% "V"], .by = it) %>%
        mutate(rmspe_all = rmspe[data %in% "all"], .by = it) %>%
        mutate(ratio_postpre = rmspe[data %in% "V"] / rmspe[data %in% "T"], .by = it) %>%
        mutate(ratio_allpre = rmspe[data %in% "all"] / rmspe[data %in% "T"], .by = it) %>%
        filter(count == 3) %>%
        select(-c(data, rmspe, check, count)) %>%
        filter(method == "simplex" & cross.val == F) %>%
        filter(!duplicated(.)) %>%
        #filter(ratio_postpre < 1.1 & ratio_postpre > .90)
        filter(min_year == 2014 & ratio_postpre < 2)
      
    }
  
  #   # Analyse grid search
  #   <<grid_ts>>
  #   <<grid_param>>
    
}

```
