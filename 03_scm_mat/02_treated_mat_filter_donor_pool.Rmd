---
title: "Filtering of MAT donor pool"
author: "Stefanie Meliss"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    self_contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen = 999)
# empty work space
rm(list = ls())
gc()

# load libraries
library(kableExtra)
library(dplyr)
library(data.table)
library(ggplot2)

# create function to source code
source_code <- function(root_dir_name = "code", target_repo = "helper_functions", branch = "main", file_name = "file.R") {
  
  # construct URL
  git_url <- paste0("https://raw.githubusercontent.com/stefaniemeliss/", target_repo, "/", branch, "/", file_name)
  
  # attempt to download from github
  tempp_file <- tempfile(fileext = ".R")
  message <- curl::curl_download(git_url, tempp_file, quiet = F)
  
  if(!grepl("Error", message)) {
    
    # if successful, source file
    source(tempp_file)
    remove(tempp_file)
    
  } else { # load local copy of file
    
    # Get the current working directory
    current_dir <- getwd()
    
    # Split the current directory into its components
    dir_components <- strsplit(current_dir, "/")[[1]]
    
    # Identify the root directory dynamically based on the provided root directory name
    root_index <- which(dir_components == root_dir_name)
    if (length(root_index) == 0) {
      stop(paste("Root directory", root_dir_name, "not found in the current path"))
    }
    root_dir <- do.call(file.path, as.list(dir_components[1:root_index]))
    
    # Identify the subdirectory one level below the root and construct its absolute path
    project_repo <- dir_components[root_index + 1]
    dir <- file.path(root_dir, project_repo)
    
    if (target_repo != project_repo) {
      dir <- gsub(project_repo, target_repo, dir) 
    }
    
    # Construct the full file path
    file_path <- file.path(dir, file_name)
    
    # Print the directory and file path for debugging
    print(paste("Directory:", dir))
    print(paste("File path:", file_path))
    
    # Source the file into the parent frame
    source(file_path, local = parent.frame())
  }
}

# source functions
source_code(target_repo = "scm_feasibility", file_name = "functions.R")

# Define the base directory
dir <- get_directory()
dir_data <- file.path(dir, "data")
dir_misc <- file.path(dir, "misc")

# get file stem name
out_file <- paste0(get_file_stem(), "_out.csv")
#if(file.exists(out_file)) file.remove(out_file)


# copy data #
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_swf.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_pupils.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_search.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_groups.csv"), dir_data, overwrite = T)

# load data #

swf <- fread(file.path(dir_data, "data_swf.csv"))
pup <- fread(file.path(dir_data, "data_pupils.csv"))
est <- fread(file.path(dir_data, "data_establishments_search.csv"), na.strings = "")
groups <- fread(file.path(dir_data, "data_establishments_groups.csv"), na.strings = "")


# process data establishments #

# load in file with timeseries desc
summary <- read.csv(file.path(dir, "03_scm_mat",  "01_treated_mat_examine_dv_preds_out.csv"))

# only select schools with sufficent obs
summary <- subset(summary, n >= 4)

# save laestab numbers
list_laestab_treated <- unique(summary$laestab)

# get information on establishment 
est_treated <- est %>% 
  filter(laestab %in% list_laestab_treated) %>%
  mutate(school = "treated") %>% 
  as.data.frame()

# get info on treated group
uid_treated <- 2939
```


### Data preparation process for synthetic control analysis

The code performs a series of data preparation steps for a synthetic control analysis, focusing on Multi-Academy Trusts (MATs) in specific regions of England. Here's a breakdown of the process:

##### Region definition

- Defines target regions: "Yorkshire and the Humber" and "North West".
- Creates combinations of these regions for filtering purposes.

<details> <summary>Rationale for region definition</summary>
The code defines two target regions: "Yorkshire and the Humber" and "North West". This region definition is based on the geographical distribution of schools within the Dixons Academies Trust, which is the treated Multi-Academy Trust (MAT) in this analysis.

Dixons has schools in both Yorkshire and the Humber (primarily Bradford and Leeds) and the North West (Liverpool and Manchester). By focusing on these two regions, the analysis can compare Dixons schools with other schools operating in similar socio-economic contexts, ensuring a more valid synthetic control analysis.

Including both regions also ensures a sufficient number of schools and MATs for a robust donor pool, while maintaining geographical relevance to the treated MAT's areas of operation.

</details>  

##### Initial data cleaning at school level

- Removes schools that have left a MAT.
- Excludes special provision schools.


##### MAT and school identification

- Identifies MATs with schools in the target regions.
- Extracts unique school identifiers (LAESTABs) associated with these MATs.


##### Dataset creation

- Filters School Workforce (SWF) data for outcome and predictor variables.
- Filters pupil data for predictor variables.
- Merges these datasets and removes any rows with missing values.
- Adds MAT information to the combined dataset.


##### Longitudinal data filtering

- Keeps only schools with 4 or more years of observations.


##### MAT-level filtering

- Identifies MATs meeting specific criteria (**more than 1 school in MAT** after school-level filtering, schools only in specified regions).


##### Data aggregation

- Computes MAT-level averages for each academic year.  
- Data from **more than one school** per academic year required.
- Retains only MATs with complete time series data.


##### Outlier detection and removal

- Removes MATs with outliers in their own time series.
- Removes MATs with outliers compared to the entire donor pool.


##### Final dataset preparation

- Combines treated and donor MAT data.
- Formats time periods for analysis.


##### Summary information

- Creates a summary of MATs in the donor pool, including names, number of schools, educational phases, and regions.

```{r data_prep, include=F}
# Define target regions for filtering the donor pool
regions <- c("Yorkshire and the Humber", "North West")

# process data at MAT level
process_data_scm_mat(uid_treated = uid_treated, target_regions = regions)
```

## Treated MAT  

```{r check_treated, echo=FALSE, results='asis', eval=T}
# add info about schools
groups %>% 
  filter(laestab %in% df$laestab[df$group_uid == uid_treated]) %>%
  select(-c(urn, establishmentnumber, la_code, group_uid, group_id, establishmenttypegroup_name, group_name, group_closed_date, date_left_group, laestab, establishment_closedate, reasonestablishmentclosed_name)) %>%
  kbl(caption = paste0("Schools used for MAT timeseries"), row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>% 
  print()

# show MAT level timeseries data
df_treat %>%
  select(-group_uid) %>%
  mutate(time_period = insert_slash(time_period)) %>%
  relocate(., n, .after = time_period) %>%
  rename(., n_schools = n) %>%
  kbl(caption = paste0("MAT timeseries data"), row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>% 
  print()

##### CREATE SPAGHETTI PLOT ####

# create data in long format
df_long <- df_treat %>%
  tidyr::pivot_longer(
    cols = -c(group_uid, n, time_period),
    names_to = "variable") %>%
  mutate(category = case_match(variable, 
                               "pupil_to_qual_teacher_ratio" ~ "Outcome",
                               "fte_avg_age" ~ "Teacher age",
                               "pnpupfsm_e" ~ "% pupils FSM"),
         time_period_str = insert_slash(time_period)
  ) %>%
  as.data.frame()

df_long$category <- factor(df_long$category, levels = c("Outcome", "Teacher age", "% pupils FSM"))


# plot timeseries for each variable
plt <- ggplot(data = df_long, aes(x = time_period_str, y = value, group = group_uid)) +
  geom_line(col = coral) + 
  geom_point(col = coral, aes(size = n/2)) +
  facet_wrap(~ category, ncol = 1, strip.position = "top", scales = "free_y") +
  ambition_theme +
  ylab("Reported value") + xlab("Academic year") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.title = element_blank(),
        legend.position = "none")

print(plt)
cat("\n\n")  # Add some space between plots


##### CREATE SUMMARY TABLE ####


# compute timeseries descriptives
ts_desc <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){psych::describe(x, fast = T)})

# combine to df
ts_desc <- do.call("rbind",ts_desc)
ts_desc$vars <- NULL

ts_desc$out_count <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){sum(is_outlier_3sd(x))})

# compute relative standard deviation
ts_desc$rsd <- ts_desc$sd / ts_desc$mean

if (nrow(df_treat) > 1) {
  
  # compute timeseries auto correlation
  max_lag = ceiling(.25 * nrow(df_treat)) # use lags up to about one-quarter of the total number of observations.
  ts_ac <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){
    df_treat <- acf(ts(x), lag.max = max_lag, plot = F)
    return(df_treat$acf)
  })
  
  # transpose output
  ts_ac <- as.data.frame(t(ts_ac))
  names(ts_ac) <- paste0("ac_l", 0:(ncol(ts_ac)-1))
  ts_ac$ac_l0 <- NULL
  
  # combine all measures
  out <- merge(ts_desc, ts_ac, by = 0)
  # row.names(out) <- out$Row.names
  # out$Row.names <- NULL
  # out <- merge(out, ts_adf, by = 0)
  names(out)[1] <- "Variable"
} else {
  out <- ts_desc
  out$Variable <- row.names(out)
  out <- out %>% relocate(Variable) %>% as.data.frame()
}

# assign new variable names
out$Variable <- factor(out$Variable, 
                       levels = c("pupil_to_qual_teacher_ratio", 
                                  "pnpupfsm_e", 
                                  "fte_avg_age"),
                       labels = c("Outcome",
                                  "FSM", 
                                  "Age")
                       
)
# sort 
out <- out[order(out$Variable), ]

# print to markdown
out %>% 
  mutate(Variable = factor(Variable, levels = c("Outcome", "Age", "FSM"))) %>%
  rename(., `T(0)` = n) %>%
  kbl(caption = paste0("Descriptives of MAT timeseries data"), row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>% 
  column_spec(c(2, 13), border_right = T) %>%
  column_spec(c(1, 2, 4, 8, 13), bold = T) %>%
  print()
cat("\n")

```


## MAT donor pool  


```{r check_donors, echo=FALSE, results='asis', eval=T}
knitr::opts_chunk$set(echo = TRUE)
# format information on MATs
MATs$multiple_phases <- grepl(" | ", MATs$phase, fixed = T)
MATs <- create_element_columns(data = MATs, column_name = "phase", drop = F)
MATs$multiple_gors <- grepl(" | ", MATs$gor, fixed = T)
MATs <- create_element_columns(data = MATs, column_name = "gor", drop = F)

# Display summary information in a formatted table
DT::datatable(MATs, rownames = F,
              # caption = paste0("MATs (J = ", nrow(MATs), ") included in donor pool"),
              filter = 'top', options = list(pageLength = 10))

##### CREATE SPAGHETTI PLOT ####

# create data in long format
df_long <- df_avg %>%
  tidyr::pivot_longer(
    cols = -c(group_uid, n, time_period, time_period_str, status),
    names_to = "variable") %>%
  mutate(category = case_match(variable, 
                               "pupil_to_qual_teacher_ratio" ~ "Outcome",
                               "fte_avg_age" ~ "Teacher age",
                               "pnpupfsm_e" ~ "% pupils FSM")) %>%
  as.data.frame()

df_long$category <- factor(df_long$category, levels = c("Outcome", "Teacher age", "% pupils FSM"))

# plot timeseries average for each school
cols <- c(navy40, coral)
names(cols) <- c("Donor MATs", id_group)

print(ggplot(data = df_long, aes(x = time_period_str, y = value, col = status, group = group_uid)) +
        geom_line(data = df_long[df_long$status == "Donor MATs", ], aes(col = paste("Donor MATs"))) + 
        geom_line(data = df_long[df_long$status == paste(id_group), ], aes(col = paste(id_group)), linewidth =.8) +
        geom_point(data = df_long[df_long$status == paste(id_group), ], aes(col = paste(id_group), size = n)) +
        facet_wrap(~ category, ncol = 1, strip.position = "top", scales = "free_y") +
        ambition_theme +
        scale_color_manual(
          breaks=c(id_group, "Donor MATs"),
          values=cols) +
        ylab("Reported value") + xlab("Academic year") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1),
              legend.title = element_blank()) +
        guides(size = "none"))
cat("\n\n")  # Add some space between plots


```


## Different filter settings

```{r, echo=FALSE, results='asis', message=FALSE, eval = T}
knitr::opts_chunk$set(echo = TRUE)

run_gridsearch <- F
if (run_gridsearch) {
  
  # define options for filtering
  filter_options <- list(
    "NULL",  # This will be interpreted as NULL later
    "! time_period %in% c(201011, 201112)"
  )
  
  # Create the grid
  filter_grid <- expand.grid(
    min_years_obs = c(4, 6, 8),
    min_schools_per_mat = c(2, 3, 4), 
    min_schools_per_timeperiod = c(2, 3, 4),
    swf_filter_idx = 1:length(filter_options),
    regions = I(list(c("Yorkshire and the Humber", "North West"), c("Yorkshire and the Humber"))),
    exclude_single_phase = c(TRUE, FALSE),
    exclude_northwest = c(TRUE, FALSE)
  )
  
  # remove the options that don't include North West to begin with and then exclude north west later (redundant)
  filter_grid <- filter_grid[! (!grepl("North West", filter_grid$regions)& filter_grid$exclude_northwest == T), ]
  
  # remove options where all years are used but min_schools_per_timeperiod is larger than 2
  filter_grid <- filter_grid[ !(filter_grid$swf_filter_idx == 1 & filter_grid$min_schools_per_timeperiod > 2), ]
  
  # Add the actual filter expressions
  filter_grid$swf_filter <- filter_options[filter_grid$swf_filter_idx]
  
  # Remove the index column
  filter_grid$swf_filter_idx <- NULL
  
  # Add coluns with NAs that will be filled when iterating through the grid
  filter_grid$treated_incl <- NA
  filter_grid$n_donors <- NA
  
  results <- do.call(rbind, lapply(1:nrow(filter_grid[, ]), function(i) {
    message(i)
    # Extract filters
    filters <- filter_grid[i, ]
    
    # Convert "NULL" string to actual NULL
    swf_filter_param <- if(filters$swf_filter == "NULL") NULL else unlist(filters$swf_filter)
    filters$swf_filter <- unlist(filters$swf_filter)
    
    # run processing with the parameters
    result <- tryCatch({
      process_data_scm_mat(uid_treated = uid_treated, 
                           target_regions = unlist(filters$regions), 
                           min_years_obs = filters$min_years_obs,
                           min_schools_per_mat = filters$min_schools_per_mat,
                           min_schools_per_timeperiod = filters$min_schools_per_timeperiod,
                           swf_filter = swf_filter_param)
    }, error = function(e) { return(filters)})
    
    # Extract information about iteration
    tmp <- result$MATs
    tmp$multiple_phases <- grepl(" | ", tmp$phase, fixed = T)
    tmp$multiple_gor <- grepl(" | ", tmp$gor, fixed = T)
    tmp <- create_element_columns(tmp, "gor")
    filters$treated_incl <- uid_treated %in% tmp$group_uid
    tmp <- tmp[! tmp$group_uid %in% uid_treated, ]
    if (filters$exclude_single_phase) tmp <- tmp[tmp$multiple_phases, ]
    if (filters$exclude_northwest) tmp <- tmp[! (tmp$multiple_gor == F & tmp$gor_north_west == T), ]
    
    filters$n_donors <- nrow(tmp)
    
    filters$regions <- paste(filters$regions, collapse = ", ")
    
    return(filters)
  }))
  
  # save results of grid search
  write.csv(results, file = file.path(dir, "03_scm_mat", out_file), row.names = F)
  
} else {
  results <- read.csv(file = file.path(dir, "03_scm_mat", out_file))
}

# Display summary information in a formatted table
DT::datatable(results[results$treated_incl == T, ], rownames = F,
              # caption = paste0("MATs (J = ", nrow(MATs), ") included in donor pool"),
              filter = 'top', options = list(pageLength = 10))

```

```{r, echo=T, results='asis', message=FALSE, eval = T, fig.height=25, fig.width=25}
tmp <- results[results$treated_incl == T, ]
cat("min t0 = minimum pre-treatment observations\n")
cat("min it = minimum observations in unit i at timepoint t\n")
cat("min size = minimum amount of schools with valid TS in mat t\n")
tmp$min_t0 <- paste("min to:", tmp$min_years_obs)
tmp$min_it <- paste("min it:", tmp$min_schools_per_timeperiod)
tmp$min_size <- paste("min size:", tmp$min_schools_per_mat)

tmp$NW <- ifelse(grepl("North West", tmp$regions), "Region: YS&H + NW", "Region: YS&H")
tmp$single <- ifelse(tmp$exclude_single_phase, "phases: div only", "phases: same + div")
tmp$excl_nw<- ifelse(tmp$exclude_northwest, "excl. NW based mat", "incl. NW based mat")
tmp$years <- ifelse(tmp$swf_filter == "NULL", "all years", "excl. 10/11 + 11/12")

ggplot(data = tmp, aes(x = treated_incl, y = n_donors)) +
  geom_point() +
  facet_grid(rows = vars(NW, single, excl_nw, years), cols = vars(min_size, min_it, min_t0))

```


if we want to average more than two schools per year (min_schools_per_timeperiod), we need to remove 2010/11 and 2011/12
min_schools_per_mat - all settings fine
min_years_obs - all settings fine


