---
title: "Filtering of MAT donor pool"
author: "Stefanie Meliss"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    self_contained: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen = 999)
# empty work space
rm(list = ls())
gc()

# load libraries
library(kableExtra)
library(dplyr)
library(data.table)
library(ggplot2)

# create function to source code
source_code <- function(root_dir_name = "code", target_repo = "helper_functions", branch = "main", file_name = "file.R") {
  
  # construct URL
  git_url <- paste0("https://raw.githubusercontent.com/stefaniemeliss/", target_repo, "/", branch, "/", file_name)
  
  # attempt to download from github
  tempp_file <- tempfile(fileext = ".R")
  message <- curl::curl_download(git_url, tempp_file, quiet = F)
  
  if(!grepl("Error", message)) {
    
    # if successful, source file
    source(tempp_file)
    remove(tempp_file)
    
  } else { # load local copy of file
    
    # Get the current working directory
    current_dir <- getwd()
    
    # Split the current directory into its components
    dir_components <- strsplit(current_dir, "/")[[1]]
    
    # Identify the root directory dynamically based on the provided root directory name
    root_index <- which(dir_components == root_dir_name)
    if (length(root_index) == 0) {
      stop(paste("Root directory", root_dir_name, "not found in the current path"))
    }
    root_dir <- do.call(file.path, as.list(dir_components[1:root_index]))
    
    # Identify the subdirectory one level below the root and construct its absolute path
    project_repo <- dir_components[root_index + 1]
    dir <- file.path(root_dir, project_repo)
    
    if (target_repo != project_repo) {
      dir <- gsub(project_repo, target_repo, dir) 
    }
    
    # Construct the full file path
    file_path <- file.path(dir, file_name)
    
    # Print the directory and file path for debugging
    print(paste("Directory:", dir))
    print(paste("File path:", file_path))
    
    # Source the file into the parent frame
    source(file_path, local = parent.frame())
  }
}

# source functions
source_code(target_repo = "scm_feasibility", file_name = "functions.R")

# Define the base directory
dir <- get_directory()
dir_data <- file.path(dir, "data")
dir_misc <- file.path(dir, "misc")

# get file stem name
file_stem <- get_file_stem()

# copy data #
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_swf.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_pupils.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_search.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_groups.csv"), dir_data, overwrite = T)

# load data #

swf <- fread(file.path(dir_data, "data_swf.csv"))
pup <- fread(file.path(dir_data, "data_pupils.csv"))
est <- fread(file.path(dir_data, "data_establishments_search.csv"), na.strings = "")
groups <- fread(file.path(dir_data, "data_establishments_groups.csv"), na.strings = "")


# process data establishments #

# load in file with timeseries desc
summary <- read.csv(file.path(dir, "03_scm_mat",  "01_treated_mat_examine_dv_preds_out.csv"))

# only select schools with sufficent obs
summary <- subset(summary, n >= 4)

# save laestab numbers
list_laestab_treated <- unique(summary$laestab)

# get information on establishment 
est_treated <- est %>% 
  filter(laestab %in% list_laestab_treated) %>%
  mutate(school = "treated") %>% 
  as.data.frame()

# get info on treated group
uid_treated <- 2939

run_gridsearch <- F
```


### Data preparation process for synthetic control analysis

The code performs a series of data preparation steps for a synthetic control analysis, focusing on Multi-Academy Trusts (MATs) in specific regions of England. Here's a breakdown of the process:

##### Region definition

- Defines target regions: "Yorkshire and the Humber" and "North West".
- Creates combinations of these regions for filtering purposes.

<details> <summary>Rationale for region definition</summary>
The code defines two target regions: "Yorkshire and the Humber" and "North West". This region definition is based on the geographical distribution of schools within the Dixons Academies Trust, which is the treated Multi-Academy Trust (MAT) in this analysis.

Dixons has schools in both Yorkshire and the Humber (primarily Bradford and Leeds) and the North West (Liverpool and Manchester). By focusing on these two regions, the analysis can compare Dixons schools with other schools operating in similar socio-economic contexts, ensuring a more valid synthetic control analysis.

Including both regions also ensures a sufficient number of schools and MATs for a robust donor pool, while maintaining geographical relevance to the treated MAT's areas of operation.

</details>  

##### Initial data cleaning at school level

- Removes schools that have left a MAT.
- Excludes special provision schools.


##### MAT and school identification

- Identifies MATs with schools in the target regions.
- Extracts unique school identifiers (LAESTABs) associated with these MATs.


##### Dataset creation

- Filters School Workforce (SWF) data for outcome and predictor variables.
- Filters pupil data for predictor variables.
- Merges these datasets and removes any rows with missing values.
- Adds MAT information to the combined dataset.


##### Longitudinal data filtering

- Keeps only schools with 4 or more years of observations.


##### MAT-level filtering

- Identifies MATs meeting specific criteria (**more than 1 school in MAT** after school-level filtering, schools only in specified regions).


##### Data aggregation

- Computes MAT-level averages for each academic year.  
- Data from **more than one school** per academic year required.
- Retains only MATs with complete time series data.


##### Outlier detection and removal

- Removes MATs with outliers in their own time series.
- Removes MATs with outliers compared to the entire donor pool.


##### Final dataset preparation

- Combines treated and donor MAT data.
- Formats time periods for analysis.


##### Summary information

- Creates a summary of MATs in the donor pool, including names, number of schools, educational phases, and regions.  

```{r check_treated, echo=FALSE, results='asis', eval=F}
# add info about schools
groups %>% 
  filter(laestab %in% df$laestab[df$group_uid == uid_treated]) %>%
  select(-c(urn, establishmentnumber, la_code, group_uid, group_id, establishmenttypegroup_name, group_name, group_closed_date, date_left_group, laestab, establishment_closedate, reasonestablishmentclosed_name)) %>%
  kbl(caption = paste0("Schools used for MAT timeseries"), row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>% 
  print()

# show MAT level timeseries data
df_treat %>%
  select(-group_uid) %>%
  relocate(., n, .after = time_period) %>%
  rename(., n_schools = n) %>%
  kbl(caption = paste0("MAT timeseries data"), row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>% 
  print()

##### CREATE SPAGHETTI PLOT ####

# create data in long format
df_long <- df_treat %>%
  tidyr::pivot_longer(
    cols = -c(group_uid, n, time_period, time_period_str, status),
    names_to = "variable") %>%
  mutate(category = case_match(variable, 
                               "pupil_to_qual_teacher_ratio" ~ "Outcome",
                               "fte_avg_age" ~ "Teacher age",
                               "pnpupfsm_e" ~ "% pupils FSM"),
         time_period_str = insert_slash(time_period)
  ) %>%
  as.data.frame()

df_long$category <- factor(df_long$category, levels = c("Outcome", "Teacher age", "% pupils FSM"))


# plot timeseries for each variable
options(repr.plot.width = 8, repr.plot.height = 6)

plt <- ggplot(data = df_long, aes(x = time_period_str, y = value, group = group_uid)) +
  geom_line(col = coral) + 
  geom_point(col = coral, aes(size = n/2)) +
  facet_wrap(~ category, ncol = 1, strip.position = "top", scales = "free_y") +
  ambition_theme +
  ylab("Reported value") + xlab("Academic year") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.title = element_blank(),
        legend.position = "none")

print(plt)
cat("\n\n")  # Add some space between plots


##### CREATE SUMMARY TABLE ####


# compute timeseries descriptives
ts_desc <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){psych::describe(x, fast = T)})

# combine to df
ts_desc <- do.call("rbind",ts_desc)
ts_desc$vars <- NULL

ts_desc$out_count <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){sum(is_outlier_3sd(x))})

# compute relative standard deviation
ts_desc$rsd <- ts_desc$sd / ts_desc$mean

if (nrow(df_treat) > 1) {
  
  # compute timeseries auto correlation
  max_lag = ceiling(.25 * nrow(df_treat)) # use lags up to about one-quarter of the total number of observations.
  ts_ac <- apply(df_treat[, grepl("pup|fte", names(df_treat))], MARGIN = 2, FUN = function(x){
    df_treat <- acf(ts(x), lag.max = max_lag, plot = F)
    return(df_treat$acf)
  })
  
  # transpose output
  ts_ac <- as.data.frame(t(ts_ac))
  names(ts_ac) <- paste0("ac_l", 0:(ncol(ts_ac)-1))
  ts_ac$ac_l0 <- NULL
  
  # combine all measures
  out <- merge(ts_desc, ts_ac, by = 0)
  # row.names(out) <- out$Row.names
  # out$Row.names <- NULL
  # out <- merge(out, ts_adf, by = 0)
  names(out)[1] <- "Variable"
} else {
  out <- ts_desc
  out$Variable <- row.names(out)
  out <- out %>% relocate(Variable) %>% as.data.frame()
}

# assign new variable names
out$Variable <- factor(out$Variable, 
                       levels = c("pupil_to_qual_teacher_ratio", 
                                  "pnpupfsm_e", 
                                  "fte_avg_age"),
                       labels = c("Outcome",
                                  "FSM", 
                                  "Age")
                       
)
# sort 
out <- out[order(out$Variable), ]

# print to markdown
out %>% 
  mutate(Variable = factor(Variable, levels = c("Outcome", "Age", "FSM"))) %>%
  rename(., `T(0)` = n) %>%
  kbl(caption = paste0("Descriptives of MAT timeseries data"), row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>% 
  column_spec(c(2, 13), border_right = T) %>%
  column_spec(c(1, 2, 4, 8, 13), bold = T) %>%
  print()
cat("\n")

```

```{r check_donors, echo=FALSE, results='asis', eval=F}
knitr::opts_chunk$set(echo = TRUE)
# format information on MATs
MATs$multiple_phases <- grepl(" | ", MATs$phase, fixed = T)
MATs <- create_element_columns(data = MATs, column_name = "phase", drop = F)
MATs$multiple_gors <- grepl(" | ", MATs$gor, fixed = T)
MATs <- create_element_columns(data = MATs, column_name = "gor", drop = F)

# Display summary information in a formatted table
kbl(MATs, caption = paste0("Schools used for MAT timeseries"), row.names = F, digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), fixed_thead = T) %>% 
  print()
cat("\n\n")

##### CREATE SPAGHETTI PLOT ####

# create data in long format
df_long <- df_avg %>%
  tidyr::pivot_longer(
    cols = -c(group_uid, n, time_period, time_period_str, status),
    names_to = "variable") %>%
  mutate(category = case_match(variable, 
                               "pupil_to_qual_teacher_ratio" ~ "Outcome",
                               "fte_avg_age" ~ "Teacher age",
                               "pnpupfsm_e" ~ "% pupils FSM")) %>%
  as.data.frame()

df_long$category <- factor(df_long$category, levels = c("Outcome", "Teacher age", "% pupils FSM"))

# plot timeseries average for each school
cols <- c(navy40, coral)
names(cols) <- c("Donor MATs", id_group)

print(ggplot(data = df_long, aes(x = time_period_str, y = value, col = status, group = group_uid)) +
        geom_line(data = df_long[df_long$status == "Donor MATs", ], aes(col = paste("Donor MATs"))) + 
        geom_line(data = df_long[df_long$status == paste(id_group), ], aes(col = paste(id_group)), linewidth =.8) +
        geom_point(data = df_long[df_long$status == paste(id_group), ], aes(col = paste(id_group), size = n)) +
        facet_wrap(~ category, ncol = 1, strip.position = "top", scales = "free_y") +
        ambition_theme +
        scale_color_manual(
          breaks=c(id_group, "Donor MATs"),
          values=cols) +
        ylab("Reported value") + xlab("Academic year") +
        theme(axis.text.x = element_text(angle = 45, hjust = 1),
              legend.title = element_blank()) +
        guides(size = "none"))
cat("\n\n")  # Add some space between plots


```

```{r grid_search, echo=FALSE, results='asis', eval = F}

file_name <- file.path(dir, "03_scm_mat", paste0(file_stem, "_", tolower(phase), ".csv"))

if (run_gridsearch) {
  
  # Define timeseries
  years.avail <- c(2010:2023)
  period.post <- c(2022:2023)
  
  years.avail <- setdiff(years.avail, period.post)
  

  
  ####################################
  ### define grid
  
  if (phase == "mixed") {
    # define options for filtering
    filter.options <- list(
      "NULL",  # This will be interpreted as NULL later
      "! time_period %in% c(201011, 201112)"
    )
    
    # define options for donor pool
    min.years.obs.options = c(4, 6, 8)
    min.schools.per.mat.options = c(2, 3, 4)
    min.schools.per.timeperiod.options = c(2, 3, 4)
    
    regions.options = list(c("Yorkshire and the Humber", "North West"), c("Yorkshire and the Humber"))
    
    exclude.single.phase.options = c(TRUE, FALSE)
    exclude.northwest.options = c(TRUE, FALSE)
    
    filter_phase = "Not applicable"
    
  } else if (phase == "Secondary") {
    
    # define options for filtering
    filter.options <- list(
      "! time_period %in% c(201011, 201112)",
      "! time_period %in% c(201011, 201112, 201213, 201314)"
    )
    
    # define options for donor pool
    min.years.obs.options = c(4, 6, 8)
    min.schools.per.mat.options = c(2, 3, 4)
    min.schools.per.timeperiod.options = c(2, 3, 4)
    
    regions.options = list(c("Yorkshire and the Humber", "North West"))
    
    exclude.single.phase.options = c(FALSE)
    exclude.northwest.options = c(TRUE, FALSE)
    
    filter_phase = unique(groups$phaseofeducation_name)[!grepl("econdary", unique(groups$phaseofeducation_name))]
    
  } else if (phase == "Primary") {
    
    # define options for filtering
    filter.options <- list(
      "! time_period %in% c(201011, 201112, 201213, 201314)",
      "! time_period %in% c(201011, 201112, 201213, 201314, 201415)"
    )
    
    # define options for donor pool
    min.years.obs.options = c(4, 6, 8)
    min.schools.per.mat.options = c(2, 3, 4)
    min.schools.per.timeperiod.options = c(2, 3, 4)
    
    regions.options = list(c("Yorkshire and the Humber", "North West"), c("Yorkshire and the Humber"))
    
    exclude.single.phase.options = c(FALSE)
    exclude.northwest.options = c(TRUE, FALSE)
    
    filter_phase = unique(groups$phaseofeducation_name)[!grepl("imary", unique(groups$phaseofeducation_name))]
    
  }
  
  
  # Create initial parameter grid
  param_grid <- expand.grid(
    min.years.obs = min.years.obs.options,
    min.schools.per.mat = min.schools.per.mat.options, 
    min.schools.per.timeperiod = min.schools.per.timeperiod.options,
    swf.filter.idx = 1:length(filter.options),
    regions = I(regions.options),
    exclude.single.phase = exclude.single.phase.options,
    exclude.northwest = exclude.northwest.options,
    filter_phase = I(list(filter_phase)),
    stringsAsFactors = FALSE
  )
  
  # remove the options that don't include North West to begin with and then exclude north west later (redundant)
  param_grid <- param_grid[! (!grepl("North West", param_grid$regions)& param_grid$exclude.northwest == T), ]
  
  # remove options where all years are used but min_schools_per_timeperiod is larger than 2
  param_grid <- param_grid[ !(param_grid$swf.filter.idx == 1 & param_grid$min.schools.per.timeperiod > 2), ]
  
  # Add the actual filter expressions
  param_grid$swf.filter <- filter.options[param_grid$swf.filter.idx]
  
  # Remove the index column
  param_grid$swf.filter.idx <- NULL
  
  # manually define period.pre based on filters
  if (phase == "mixed") {
    param_grid$period.pre <- ifelse(param_grid$swf.filter == "NULL", I(list(c(sort(years.avail)))), I(list(c(sort(setdiff(years.avail, c(2010:2011)))))))
  } else if (phase == "Secondary") {
    param_grid$period.pre <- ifelse(grepl("201314", param_grid$swf.filter), I(list(c(sort(setdiff(years.avail, c(2010:2013)))))), I(list(c(sort(setdiff(years.avail, c(2010:2011)))))))
  } else if (phase == "Primary") {
    param_grid$period.pre <- ifelse(grepl("201415", param_grid$swf.filter), I(list(c(sort(setdiff(years.avail, c(2010:2014)))))), I(list(c(sort(setdiff(years.avail, c(2010:2013)))))))
  }
  
  
  # Add coluns with NAs that will be filled when iterating through the grid
  param_grid$treated_incl <- NA
  param_grid$n_donors <- NA
  
  results <- do.call(rbind, lapply(1:nrow(param_grid[, ]), function(i) {
    message(i)
    
    # Extract params
    params <- param_grid[i, ]
    
    # Convert "NULL" string to actual NULL
    swf.filter.param <- if(params$swf.filter == "NULL") NULL else unlist(params$swf.filter)
    params$swf.filter <- unlist(params$swf.filter)
    
    # run processing with the parameters
    result <- tryCatch({
      process_data_scm_mat(uid_treated = uid_treated, 
                           target_regions = unlist(params$regions), 
                           min_years_obs = params$min.years.obs,
                           min_schools_per_mat = params$min.schools.per.mat,
                           min_schools_per_timeperiod = params$min.schools.per.timeperiod,
                           filter_phase = unlist(params$filter_phase),
                           swf_filter = swf.filter.param)
    }, error = function(e) { 
      return(params)
      # return(list(error = paste("Error in process_data_scm_mat:", e$message)))
    })
    
    # Extract information about iteration
    tmp <- result$MATs
    tmp$multiple_phases <- grepl(" | ", tmp$phase, fixed = T)
    tmp$multiple_gor <- grepl(" | ", tmp$gor, fixed = T)
    tmp <- create_element_columns(tmp, "gor")
    params$treated_incl <- uid_treated %in% tmp$group_uid
    tmp <- tmp[! tmp$group_uid %in% uid_treated, ]
    if (params$exclude.single.phase) tmp <- tmp[tmp$multiple_phases, ]
    if (params$exclude.northwest) tmp <- tmp[! (tmp$multiple_gor == F & tmp$gor_north_west == T), ]
    
    params$n_donors <- nrow(tmp)
    
    params$regions <- paste(params$regions, collapse = ", ")
    params$filter_phase <- paste(params$filter_phase, collapse = ", ")
    params$period.pre <- paste(params$period.pre, collapse = ", ")
    
    return(params)
  }))
  
  # save results of grid search
  write.csv(results, file = file_name, row.names = F)
  
} else {
  results <- read.csv(file = file_name)
}

```

```{r grid_plot, echo=FALSE, results='asis', message=FALSE, eval = F}

# copy data for editing
tmp_results <- results

# which region was used for filtering
tmp_results$region <- ifelse(grepl("North West", tmp_results$regions), "YS&H + NW", "YS&H")
tmp_results$region <- factor(tmp_results$region)
# were any MATs excluded?
if (phase == "mixed") {
  tmp_results$phase <- ifelse(tmp_results$exclude.single.phase, "excl. phase", "incl. phase")
  tmp_results$phase <- factor(tmp_results$phase)
} else {
  tmp_results$phase <- ifelse(!tmp_results$exclude.single.phase, "same phase", "excl. same phase")
  tmp_results$phase <- factor(tmp_results$phase)
}
tmp_results$mats_in_nw<- ifelse(tmp_results$exclude.northwest, "excl. NW MATs", "incl. NW MATs")
tmp_results$mats_in_nw<- factor(tmp_results$mats_in_nw)
# How was the average timeseries obtained?
tmp_results$min_pretreat <- paste0(tmp_results$min.years.obs, "Y")
tmp_results$min_pretreat <- factor(tmp_results$min_pretreat)
tmp_results$min_obs_per_year <- paste0(tmp_results$min.schools.per.timeperiod, "S/Y")
tmp_results$min_obs_per_year <- factor(tmp_results$min_obs_per_year)
tmp_results$min_size_mat <- paste0(tmp_results$min.schools.per.mat, "S")
tmp_results$min_size_mat <- factor(tmp_results$min_size_mat)
# which years were used in training
# # Function to extract min and max year
# extract_min_max_years <- function(period_string) {
#   years <- as.numeric(unlist(strsplit(period_string, ", ")))
#   min_year <- min(years)
#   max_year <- max(years)
#   return(c(min_year, max_year))
# }
# tmp_results$min_year <- sapply(tmp_results$period.pre, function(x) extract_min_max_years(x)[1])
# tmp_results$max_year <- sapply(tmp_results$period.pre, function(x) extract_min_max_years(x)[2])
# tmp_results$pretreat <- paste0(tmp_results$min_year, ":", tmp_results$max_year)
tmp_results$pretreat <- tmp_results$period.pre
tmp_results$pretreat <- factor(tmp_results$pretreat)

#### plot size of donor pool ####

plt <- ggplot(data = tmp_results, aes(x = min_size_mat, y = n_donors)) + 
  geom_hline(yintercept = 50, linetype = "dotted") +
  geom_point(aes(col = treated_incl)) +
  ggh4x::facet_grid2(cols = vars(min_pretreat, min_obs_per_year), rows = vars(pretreat, region, phase, mats_in_nw), strip = ggh4x::strip_nested()) +
  ambition_theme +
  theme(strip.text = element_text(size = 10),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        axis.title = element_text(size = 10),
        axis.text = element_text(size = 10),
        # axis.title.x = element_blank(),
        # axis.text.x = element_blank(),
        plot.caption = element_text(size = 10),
        legend.margin=margin(t = -8)) +
  ylab("Size of donor pool") + xlab("Mininum number of schools averaged in MAT timeseries") + 
  guides(col=guide_legend(title = "Treated unit survived filtering")) +
  scale_color_manual(values = c("TRUE" = blue, "FALSE" = red))
print(plt)
cat("\n\n")

```

```{r, echo=F, message=FALSE, results='asis', fig.align='center', fig.height=15, fig.width=10, out.width='100%', out.height='100%'}
# define phases to loop through
phases <- c("mixed", "Secondary", "Primary")
headings <- c("Whole MAT", "Secondary schools only", "Primary schools only")
for (p in 1:length(phases)) {
  
  cat("# ", headings[p], "\n\n")
  
  phase = phases[p]
  
  # define different filter option for each phase #
  
  if (phase == "mixed") {
    swf_filter = NULL
    filter_phase = "Not applicable"
  } else if (phase == "Secondary") {
    swf_filter = "! time_period %in% c(201011, 201112)"
    filter_phase = unique(groups$phaseofeducation_name)[!grepl("econdary", unique(groups$phaseofeducation_name))]
  } else if (phase == "Primary") {
    swf_filter = "! time_period %in% c(201011, 201112, 201213, 201314)"
    filter_phase = unique(groups$phaseofeducation_name)[!grepl("imary", unique(groups$phaseofeducation_name))]
  }
  
  # Define target regions for filtering the donor pool
  regions <- c("Yorkshire and the Humber", "North West")
  
  # process data at MAT level
  process_data_scm_mat(uid_treated = uid_treated, target_regions = regions, filter_phase = filter_phase,
                       swf_filter = swf_filter)
  
  cat("## Treated MAT \n\n")
  <<check_treated>>
    
    cat("## MAT donor pool \n\n")
  <<check_donors>>
    
    cat("## Different filter settings \n\n")
  <<grid_search>>
  <<grid_plot>>
  
}

```