---
title: "Results of cross-validated gridsearch with *scpi* package"
author: "Stefanie Meliss"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    self_contained: true
---

This markdown summarises the results of the grid search.  
  
- Which measure of FSM was used? (FSM vs. FSM ever)  
- Was the outcome included as feature? (excl. DV vs. incl. DV)  
- Was any covariates adjusted for each feature? (none vs. Constant vs. Trend vs. Constant + Trend)  
- Which rolling window average width was applied to the features? (roll = 1 vs. roll = 2)  
- Was the rolling window also applied to the outcome variable? (Raw DV vs. Roll DV)
- Which years were included in the training data? (all years between 2010/11 and 2021/22)  
- Which schools were included in the donor pool? (Schools in the same region vs. schools in same and neighbouring region)  
- Was the donor pool filtered with respect to value of averaged pre-treatment outcome variable in relation to treated unit? (x SD thresholds)  
- Which weight constraints were defined during the estimation? (Simplex vs. L1-l2)  
  
  
Data up to 2021/22 was used to estimate the weights under various settings. The weights were validated using data from 2022/23 and 2023/24.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

options(scipen = 999)
# empty work space
rm(list = ls())
gc()

# load libraries
library(kableExtra)
library(dplyr)
library(data.table)
library(ggplot2)

# create function to source code
source_code <- function(root_dir_name = "code", target_repo = "helper_functions", branch = "main", file_name = "file.R") {
  
  # construct URL
  git_url <- paste0("https://raw.githubusercontent.com/stefaniemeliss/", target_repo, "/", branch, "/", file_name)
  
  # attempt to download from github
  tempp_file <- tempfile(fileext = ".R")
  
  # run processing with the parameters
  message <- tryCatch({
    curl::curl_download(git_url, tempp_file, quiet = F)
  }, error = function(e) {
    return(error = paste("Error in curl::curl_download:", e$message))
  })

  if(!grepl("Error", message)) {
    
    # if successful, source file
    source(tempp_file)
    remove(tempp_file)
    
  } else { # load local copy of file
    
    # Get the current working directory
    current_dir <- getwd()
    
    # Split the current directory into its components
    dir_components <- strsplit(current_dir, "/")[[1]]
    
    # Identify the root directory dynamically based on the provided root directory name
    root_index <- which(dir_components == root_dir_name)
    if (length(root_index) == 0) {
      stop(paste("Root directory", root_dir_name, "not found in the current path"))
    }
    root_dir <- do.call(file.path, as.list(dir_components[1:root_index]))
    
    # Identify the subdirectory one level below the root and construct its absolute path
    project_repo <- dir_components[root_index + 1]
    dir <- file.path(root_dir, project_repo)
    
    if (target_repo != project_repo) {
      dir <- gsub(project_repo, target_repo, dir) 
    }
    
    # Construct the full file path
    file_path <- file.path(dir, file_name)
    
    # Print the directory and file path for debugging
    print(paste("Directory:", dir))
    print(paste("File path:", file_path))
    
    # Source the file into the parent frame
    source(file_path, local = parent.frame())
  }
}

# source functions
source_code(target_repo = "scm_feasibility", file_name = "functions.R")

# Define the base directory
dir <- get_directory()
dir_data <- file.path(dir, "data")
dir_misc <- file.path(dir, "misc")

# get file stem name
file_stem <- get_file_stem()

# copy data #
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_swf.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_pupils.csv"), dir_data, overwrite = T)
file.copy(
  file.path(gsub("scm_feasibility", "edu_stats", dir_data), "data_establishments_download.csv"), dir_data, overwrite = T)

# load data #

swf <- fread(file.path(dir_data, "data_swf.csv"))
pup <- fread(file.path(dir_data, "data_pupils.csv"))
est <- fread(file.path(dir_data, "data_establishments_download.csv"), na.strings = "")

# process data establishments #

# load in file with timeseries desc
summary <- read.csv(file.path(dir, "02_scm_school", "interim", "02_treated_schools_filter_donor_pool_out.csv"))

# only select schools with sufficient donor pool
summary <- subset(summary, n_pool >= 50)

# save laestab numbers
list_laestab_treated <- unique(summary$laestab)
# list_laestab_treated <- list_laestab_treated[1:5] # debug
# list_laestab_treated <- list_laestab_treated[1:2] # debug

# create df_region as reference
df_region <- unique(summary[, c("laestab", "same", "neighbouring")])
```

```{r plot_ts, eval=FALSE, include=F}
#id_treated = list_laestab[1] # debug

# create df for plotting - treated only
df_treat <- df_treat %>%
  arrange(laestab, desc(time_period)) %>%
  mutate(
    # apply rolling window average
    across(all_of(vars), ~ zoo::rollapply(.x, width = 2, FUN = function(x) mean(x, na.rm = TRUE), align = "left", partial = T), .names = "{col}_roll")
  ) %>%
  as.data.frame()


#### CREATE SPAGHETTI PLOT ####

# create data in long format
# create data in long format
df_long <- df_treat %>%
  tidyr::pivot_longer(
    cols = all_of(c(paste(vars), paste0(vars, "_roll"))),
    names_to = "variable") %>%
  mutate(category = case_match(variable, 
                               "pupil_to_qual_teacher_ratio" ~ "Outcome",
                               "pupil_to_qual_teacher_ratio_roll" ~ "Outcome",
                               "fte_avg_age_known" ~ "Teacher age",
                               "fte_avg_age_known_roll" ~ "Teacher age",
                               "pnpupfsm_e" ~ "% pupils FSM",
                               "pnpupfsm_e_roll" ~ "% pupils FSM",
                               "pnpupfsm_ever" ~ "% pupils FSM ever",
                               "pnpupfsm_ever_roll" ~ "% pupils FSM ever"
  ),
  computation = ifelse(grepl("roll", variable), "Rolling average", "Raw")) %>%
  as.data.frame()

df_long$category <- factor(df_long$category, levels = c("Outcome", "% pupils FSM", "% pupils FSM ever", "Teacher age"))


##### CREATE SPAGHETTI PLOT ####

# determine time period
period.avail.plt <- sort(unique(df_long$time_period))
period.pre.plt <- setdiff(period.avail.plt, c(2022:2023)) # Pre-treatment period

plt <- ggplot(data = df_long, aes(x = time_period, y = value, col = computation, group = interaction(laestab, computation))) +
  geom_vline(xintercept = period.pre.plt[length(period.pre.plt)]+0.5, linetype = "dotted") +
  geom_line() + 
  geom_point() +
  facet_wrap(~ category, ncol = 1, strip.position = "top", scales = "free_y") +
  ambition_theme +
  ylab("Reported value") + xlab("Academic year") +
  scale_x_continuous(breaks = df_long$time_period, labels = df_long$time_period_str) +
  scale_color_manual(values = c("Raw" = blue, "Rolling average" = red)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.title = element_blank())

suppressWarnings(print(plt))
cat("\n\n")  # Add some space between plots
```

```{r proc grid fit, eval=FALSE, echo=F}
#### process data grid search ####

# declare file name
file_name <- file.path(dir, "02_scm_school", "interim", paste0("03_treated_schools_scpi_cv_", gsub(" ", "_", id_name), "_results.csv"))

# read in results
results <- read.csv(file_name)

# copy data for editing
results_fit <- results
# apply(results[1:14], 2, unique)

# --- create new vars for facets --- #

# timeseries processing options #

# was rolling average computed
results_fit$rolling.window <- ifelse(results_fit$rolling.window == 1, "Raw IV", "Roll IV")
results_fit$rolling.window <- factor(results_fit$rolling.window)

# was rolling average computed for outcome
results_fit$roll.outcome <- ifelse(results_fit$roll.outcome, "Roll DV", "Raw DV")
results_fit$roll.outcome <- factor(results_fit$roll.outcome)

# donor pool filtering options # 

# which region was used for filtering
results_fit$region.filter <- ifelse(grepl("neighbouring", results_fit$region.filter), "Same + Neighb.", "Same")
results_fit$region.filter <- factor(results_fit$region.filter)

# which SD filter was applied?
if ("50" %in% unique(results_fit$sd.range)) {
  # Primary
  results_fit$sd.range <- ifelse(grepl("50", results_fit$sd.range), "0.5 SD", "1 SD")
} else {
  # Secondary
  results_fit$sd.range <- ifelse(grepl("100", results_fit$sd.range), "1 SD", "No SD")
}
results_fit$sd.range <- factor(results_fit$sd.range)


# SCM setup options in scpi #

# which FSM measure?
results_fit$fsm <- ifelse(grepl("pnpupfsm_ever", results_fit$features), "FSM ever", "FSM")
results_fit$fsm <- factor(results_fit$fsm)

# is DV in features?
results_fit$feat_dv <- ifelse(grepl("ratio", results_fit$features), "incl. DV", "excl. DV")
results_fit$feat_dv <- factor(results_fit$feat_dv)

# covariate adjustment
results_fit$adj <- ifelse(is.na(results_fit$cov.adj), "none", results_fit$cov.adj)
results_fit$adj <- factor(results_fit$adj, levels = c("none", "constant", "trend", "constant, trend"),
                          labels = c("none", "Constant", "Trend", "C + T"))

# which years were used in training
results_fit$year.min <- sapply(results_fit$period.pre, function(x) extract_min_max_years(x)[1])
results_fit$year.max <- sapply(results_fit$period.pre, function(x) extract_min_max_years(x)[2])
results_fit$period.pre <- paste0(results_fit$year.min, ":", results_fit$year.max)
results_fit$period.pre <- factor(results_fit$period.pre)

# which constraints were applied to the weights
results_fit$method <- tstrsplit(results_fit$w.constr, "; ")[[1]]
results_fit$method <- gsub("name = ", "", results_fit$method)
results_fit$method <- factor(results_fit$method, levels = c("simplex", "L1-L2", "lasso", "user provided"))

# create a bool capturing if there was an error
results_fit$error <- grepl("Error", results_fit$status_it)

# --- process data for plotting --- #

# convert to long format
tmp_long <- results_fit %>%
  # from wide to long
  tidyr::pivot_longer(
    cols = c(rmspe_pre, rmspe_post),
    names_to = "data",
    values_to = "rmspe") %>%
  # remove all rows for rmspe in CV runs
  filter(!(cross.val == F & data == "rmspe_post")) %>%
  # rename
  mutate(data = case_match(data, 
                           "rmspe_pre" ~ "T",
                           "rmspe_post" ~ "V"  )) %>%
  mutate(data = ifelse(cross.val == F, "all", data)) %>%
  mutate(data = factor(data, levels = c("T", "V", "all"))) %>%
  # Explicitly arrange dataset by all relevant variables
  arrange(it, feat_dv, adj, fsm, region.filter, sd.range, rolling.window, roll.outcome, period.pre, method, data)

# Define explicit numeric dodge positions
method_levels <- unique(results_fit$method)
dodge_width <- 0.6
n_methods <- length(method_levels)
# Create evenly spaced numeric offsets around 0
method_positions <- seq(-dodge_width/2, dodge_width/2, length.out = n_methods)

# Create a lookup table
position_lookup <- tibble(
  method = method_levels,
  method_position = method_positions
) %>%
  mutate(method = factor(method, levels = c("simplex", "L1-L2", "lasso", "user provided"))
  )

# Merge these positions into your data
tmp_long <- tmp_long %>%
  left_join(position_lookup, by = "method") %>%
  mutate(
    data_numeric = as.numeric(factor(data)), # numeric x-axis position per 'data'
    x_position = data_numeric + method_position # final numeric position for plotting
  )

```

```{r plot grid fit, eval=FALSE, echo=F}
#### plot data grid search ####
pos_y = max(tmp_long$rmspe)+1

plt <- ggplot(data = tmp_long[tmp_long$feat_dv == "excl. DV", ], 
              aes(x = x_position, y = rmspe, group = it)) +
  geom_hline(data = function(y) y %>% filter(data == "all") %>% group_by(feat_dv, adj, region.filter, sd.range, rolling.window, roll.outcome) %>% summarise(sd_treated = unique(sd_treated), .groups = 'drop'),
             aes(yintercept = sd_treated), color = black40, linetype = "dashed") +
  geom_point(aes(colour = method), size = 1) +
  geom_line(aes(colour = method)) +
  geom_label(data = tmp_long[tmp_long$feat_dv == "excl. DV" & tmp_long$data == "all", ], 
             aes(x = 2, y = pos_y, label = as.character(n_pool)), hjust = 0.5, vjust = 0.5) +
  scale_x_continuous(
    breaks = unique(tmp_long$data_numeric),
    labels = unique(tmp_long$data)
  ) +
  ggh4x::facet_grid2(cols = vars(feat_dv, adj, rolling.window, roll.outcome), rows = vars(fsm, region.filter, sd.range), strip = ggh4x::strip_nested()) +
  ambition_theme +
  theme(strip.text = element_text(size = 10),
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 10),
        axis.title = element_text(size = 10),
        axis.text = element_text(size = 10),
        #axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
        plot.caption = element_text(size = 10),
        legend.margin=margin(t = -8)) +
  ylab("Root Mean Squared Prediction Error (RMSPE)") +
  xlab("Cross-validation fold") +
  guides(colour = guide_legend(title = "Weight constraint")) +
  scale_colour_manual(values = ambition_palette_bright)
print(plt)
cat("\n\n")


for (i in 1:length(levels(tmp_long$adj))) {
  
  plt <- ggplot(data = tmp_long[tmp_long$feat_dv == "incl. DV" & tmp_long$adj == levels(tmp_long$adj)[i], ], 
                aes(x = x_position, y = rmspe, group = it)) +
    geom_hline(data = function(y) y %>% filter(data == "all") %>% group_by(feat_dv, adj, region.filter, sd.range, rolling.window, roll.outcome) %>% summarise(sd_treated = unique(sd_treated), .groups = 'drop'),
               aes(yintercept = sd_treated), color = black40, linetype = "dashed") +
    geom_point(aes(colour = method), size = 1) +
    geom_line(aes(colour = method)) +
    geom_label(data = tmp_long[tmp_long$feat_dv == "incl. DV" & tmp_long$adj == levels(tmp_long$adj)[i] & tmp_long$data == "all", ], 
               aes(x = 2, y = pos_y, label = as.character(n_pool)), hjust = 0.5, vjust = 0.5) +
    scale_x_continuous(
      breaks = unique(tmp_long$data_numeric),
      labels = unique(tmp_long$data)
    ) +
    ggh4x::facet_grid2(cols = vars(feat_dv, adj, rolling.window, roll.outcome), rows = vars(fsm, region.filter, sd.range), strip = ggh4x::strip_nested()) +
    ambition_theme +
    theme(strip.text = element_text(size = 10),
          legend.title = element_text(size = 10),
          legend.text = element_text(size = 10),
          axis.title = element_text(size = 10),
          axis.text = element_text(size = 10),
          #axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
          plot.caption = element_text(size = 10),
          legend.margin=margin(t = -8)) +
    ylab("Root Mean Squared Prediction Error (RMSPE)") +
    xlab("Cross-validation fold") +
    guides(colour = guide_legend(title = "Weight constraint")) +
    scale_colour_manual(values = ambition_palette_bright)
  print(plt)
  cat("\n\n")
  
}

```


```{r, echo=F, message=FALSE, results='asis', fig.align='center', fig.height=10, fig.width=10}
i = 1 # debug
for (i in 1:length(list_laestab_treated)) {
  
  id_treated <- list_laestab_treated[i]
  
  # define options for filtering for each school
  
  if (id_treated == 3804004) { # Dixons Kings Academy
    swf_filter = "! time_period %in% c(201112, 201213, 201314)" # gap in data for 2013/14
  } else {
    swf_filter = NULL
  }
  
  # process data
  data <- process_data_scm(id_treated = id_treated,
                           var_teach = c("fte_avg_age_known"),
                           var_pup = c("pnpupfsm_e", "pnpupfsm_ever"),
                           swf_filter = swf_filter)

  regions <- est_treated$gor_name
  
  # determine ids of control schools
  id_cont <- unique(df$laestab[df$laestab != id_treated])
  length(id_cont)
  
  # determine ids of control schools
  id_cont <- unique(df$laestab[df$laestab != id_treated])
  
  cat("# ", id_name, "\n\n")
  
  # print some information about the school
  cat("Type of establishment:", est_treated$typeofestablishment_name, "\n\n")
  cat("Phase:", est_treated$phaseofeducation_name, "\n\n")
  cat("Gender of pupils:", est_treated$gender_name, "\n\n")
  cat("Religious character:", est_treated$religiouscharacter_name, "\n\n")
  cat("Trust flag:", est_treated$trustschoolflag_name, "\n\n")
  cat("Local authority:", est_treated$la_name, "\n\n")
  cat("Region:", est_treated$gor_name, "\n\n")
  
  cat("## Timeseries plots \n\n")
# Plot data
<<plot_ts>>
    
    # run grid searcg
    cat("## Grid search \n\n")
# process fit grid data
<<proc grid fit>>
# plot the rmspe
<<plot grid fit>>
}


```

